---
title: "Electrophysiological measures of visual suppression"
author: "Daniel H. Baker, Greta Vilidaite & Alex R. Wade"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    fig_caption: yes 
    toc: false   
    keep_tex: true
  html_document:
    df_print: paged
  pdf_document: default
bibliography: bibliography.bib
csl: elife.csl
# biblio-style: apalike
---

```{r setup, include=FALSE}

runcode <- 0  # this flag chooses whether to run the underlying analysis code (1), or just load in the figures from the last time this was run (0)
processraw <- 0  # this flag determines whether the raw data are downloaded from OSF and processed - this will require ~30GB of hard drive space and take several hours
runmodels <- 0 # this flag sets whether to run the Stan models - there are 2 * 64 * 5 = 640 separate models, so they take ~5 hours to run

# to fix the table orientation, add:
# \usepackage{rotating} to the start of the latex file
# then change \begin{table} to \begin{sidewaystable} (and same for \end)

# reasonably compact code to check which packages are installed, install the missing ones, and activate all
packagelist <- c('knitr','neldermead','tictoc','grImport','tiff','pals','bmp','rstan','coda','reshape2','MASS','bayestestR')
missingpackages <- packagelist[!packagelist %in% installed.packages()[,1]]
if (length(missingpackages)>0){install.packages(missingpackages)}
toinstall <- packagelist[which(!packagelist %in% (.packages()))]
invisible(lapply(toinstall,library,character.only=TRUE))

addalpha <- function(col, alpha=1){apply(sapply(col, col2rgb)/255, 2, function(x) rgb(x[1], x[2], x[3], alpha=alpha))}
alphalev <- 0.2
colourlist <- c("black","cornflowerblue","olivedrab3","sandybrown","mediumpurple2")

duration <- 10
targetF <- c(5,10)
tindex <- (targetF*duration)+1
contrastsC <<- c(6,12,24,48,96)
contrastsdB <- 20*log10(contrastsC)
contrastsfinedB <- 0:40
contrastsfineC <- 10^(contrastsfinedB/20)
lowmonconts <- c(6,12,24,48,88)  # slight fiddle for the monocular mask condition where the 
himonconts <- c(6,12,24,48,68)   #highest target contrast was slightly reduced to avoid clipping
lowmoncontsdB <- 20*log10(lowmonconts)
himoncontsdB <- 20*log10(himonconts)
hdata <- read.csv('temp/headerfileLow.csv',header=TRUE)
legaltriggers <- hdata$Trigger[!is.na(hdata$Trigger)]
specfreqs <- (0:199)/duration
hdirange <- 0.95

knitr::opts_chunk$set(echo = TRUE)

v4Interp <- function(df, xo, yo, rmax = .75, gridRes = 67) {
  ## Create a function to perform Matlab's v4 interpolation.
  ## Takes as input a data-frame with columns x, y, and z (x co-ordinates, y co-ordinates, and amplitude)
  ## and variables xo and yo, the co-ordinates which will be use to create a grid for interpolation
  xo <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
  yo <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
  xy <- df$x + df$y*sqrt(as.complex(-1))
  d <- matrix(rep(xy,length(xy)),nrow = length(xy), ncol = length(xy))
  d <- abs(d - t(d))
  diag(d) <- 1
  g <- (d^2) * (log(d)-1)   # Green's function.
  diag(g) <- 0
  weights <- qr.solve(g,df$z)
  xy <- t(xy)
  outmat <- matrix(nrow = gridRes,ncol = gridRes)
  for (i in 1:gridRes){
    for (j in 1:gridRes) {
      test4 <- abs((xo[i,j] + sqrt(as.complex(-1))*yo[i,j]) - xy)
      g <- (test4^2) * (log(test4)-1)
      outmat[i,j] <- g %*% weights}}
  outDf <- data.frame(x = xo[,1],outmat)
  names(outDf)[1:length(yo[1,])+1] <- yo[1,]
  return(outDf)}

colour.bar <- function(lut, min, max=-min, nticks=11, ticks=seq(min, max, len=nticks), title='') {
  scale = (length(lut)-1)/(max-min)
  plot(c(0,10), c(min,max), type='n', bty='n', xaxt='n', xlab='', yaxt='n', ylab='', main=title)
  axis(2, ticks, las=1,cex=2)
  for (i in 1:(length(lut)-1)) {
    y = (i-1)/scale + min
    rect(0,y,10,y+1/scale, col=lut[i], border=NA)
  }	
}

```

# Abstract



# Introduction

Suppression is a fundamental component of the nervous system, and is critically important for moderating neural firing. Without suppression, neural activity would be too metabolically expensive, and uncontrolled excitation might lead to seizures. In the visual system, neurons responsive to a spatially localised narrowband target stimulus are suppressed by nearby neurons that differ in their tuning [@Heeger1992]. This tuning can involve different orientations (cross-orientation suppression), different spatial locations (lateral, or surround suppression), and different eye-of-origin (interocular suppression). Suppression is typically studied using a masking paradigm, where the response to a target stimulus is reduced by the presence of a high contrast mask (see examples in Figure \@ref(fig:stimfig)a).

Several studies have demonstrated that these different types of suppression have distinct characteristics, and may occur at different stages in the early visual pathway. For example, suppression from an overlaid mask shown to the same eye as a target is immune to adaptation [@Freeman2002; @Baker2007], occurs at temporal frequencies above the range at which cortical neurons respond [@Freeman2002; @Li2005; @Sengpiel2005], and therefore appears consistent with a pre-cortical locus [@Freeman2002; @Li2005]. If a mask is presented dichoptically (to the opposite eye from the target), suppression can be reduced by adaptation [@Baker2007; @Li2005; @Sengpiel2005], has a temporal profile consistent with cortical neurons [@Li2005; @Sengpiel2005], and is reduced by applying bicuculline (a compound that blocks the suppressive neurotransmitter GABA) to early visual cortex [@Sengpiel2005]. This points to a cortical locus for interocular suppression. Finally, surround masks have tighter tuning than overlaid masks, are most effective in the periphery [@Petrov2005], and (in V1) cause suppression via feedback from higher visual areas [@Nassi2013]. Additionally, some studies have linked the magnitude of surround suppression with endogenous levels of GABA in early visual cortex [@Yoon2010; @Cook2016], again pointing to a cortical locus.

```{r include=FALSE}

# build figure 1
if (runcode==1){
  
contrastsfinedB <- 0:40
contrastsfineC <- 10^(contrastsfinedB/20)

postscript('temp/CGvsRGexample.ps', horizontal = FALSE, onefile = FALSE, paper = "special", height = 5.5, width = 5.5)

plotlims <- c(0,42,0,1.2) 
ticklocsx <- seq(0,42,6)    # locations of tick marks on x axis
ticklocsy <- seq(0,1.2,0.2)    # locations of tick marks on y axis
ticklabelsx <- c(2^(0:6),'')       # set labels for x ticks
ticklabelsy <- ticklocsy    # set labels for y ticks
par(pty="s")  # make axis square
plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4]) 
axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
mtext(text = ticklabelsx, side = 1, at=ticklocsx)     # add the tick labels
mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, las=1)  
title(xlab="Target contrast (%)", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)  
title(ylab="Response", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)

p <- c(2,10,1)
pred <- (contrastsfineC^p[1])/(p[2]^(p[1]*p[3]) + contrastsfineC^(p[1]*p[3]))
lines(contrastsfinedB,pred,col='black',lwd=4)

pred <- (contrastsfineC^p[1])/(5*p[2]^(p[1]*p[3]) + contrastsfineC^(p[1]*p[3]))
lines(contrastsfinedB,pred,col='black',lwd=4,lty=2)

pred <- 0.7*(contrastsfineC^p[1])/(p[2]^(p[1]*p[3]) + contrastsfineC^(p[1]*p[3]))
lines(contrastsfinedB,pred,col='black',lwd=4,lty=3)

legend(0, 1.2, c("Target only","Contrast gain","Response gain"), cex=1, col='black',lty=1:3, lwd=4, box.lwd=2)

dev.off()



postscript('temp/saturationplot.ps', horizontal = FALSE, onefile = FALSE, paper = "special", height = 5.5, width = 5.5)

par(pty="s")  # make axis square
plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])   
axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
mtext(text = ticklabelsx, side = 1, at=ticklocsx)     # add the tick labels
mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, las=1)
title(xlab="Target contrast (%)", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)
title(ylab="Response", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)

p <- c(2,10,1.1)
pred <- (contrastsfineC^(p[1]*p[3]))/(p[2]^p[1] + contrastsfineC^p[1])
pred <- pred/pred[41]
lines(contrastsfinedB,pred,col='black',lwd=4)

p <- c(2,10,1)
pred <- (contrastsfineC^(p[1]*p[3]))/(p[2]^p[1] + contrastsfineC^p[1])
pred <- pred/pred[41]
lines(contrastsfinedB,pred,col='black',lwd=4,lty=2)

p <- c(2,10,0.9)
pred <- (contrastsfineC^(p[1]*p[3]))/(p[2]^p[1] + contrastsfineC^p[1])
pred <- pred/pred[41]
lines(contrastsfinedB,pred,col='black',lwd=4,lty=3)

legend(0, 1.2, c("Accelerating","Saturated","Super-saturating"), cex=1, col='black',lty=1:3, lwd=4, box.lwd=2)

dev.off()

stim1 <- read.bmp('stimuli/blank.bmp')/255
stim2 <- read.bmp('stimuli/targetonly.bmp')/255
stim3 <- read.bmp('stimuli/maskonly.bmp')/255
stim4 <- read.bmp('stimuli/plaid.bmp')/255
stim5 <- read.bmp('stimuli/isosurround.bmp')/255
stim6 <- read.bmp('stimuli/orthsurround.bmp')/255


  pdf('figures/stimfig.pdf', bg="transparent", height = 6, width = 9)
  par(mar=c(0.05,0.05,0.05,0.05))
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(0,1), ylim=c(0,1))

      aspratio <- 6/9
      imwidth <- 0.25
      
      xstart <- 0.175
      ystart <- 0.7
      rasterImage(cbind(stim2,stim1),xstart,ystart,xstart+2*imwidth*aspratio,ystart+imwidth)

            xstart <- 0.0
      ystart <- 0.35
      rasterImage(cbind(stim4,stim1),xstart,ystart,xstart+2*imwidth*aspratio,ystart+imwidth)
      
            xstart <- 0.35
      ystart <- 0.35
      rasterImage(cbind(stim2,stim3),xstart,ystart,xstart+2*imwidth*aspratio,ystart+imwidth)
      
            xstart <- 0.0
      ystart <- 0
      rasterImage(cbind(stim5,stim1),xstart,ystart,xstart+2*imwidth*aspratio,ystart+imwidth)
      
            xstart <- 0.35
      ystart <- 0
      rasterImage(cbind(stim6,stim1),xstart,ystart,xstart+2*imwidth*aspratio,ystart+imwidth)
      
      PostScriptTrace(paste('temp/saturationplot.ps',sep=''))
      e1 <- readPicture('saturationplot.ps.xml')
      PostScriptTrace(paste('temp/CGvsRGexample.ps',sep=''))
      e2 <- readPicture('CGvsRGexample.ps.xml')
      
      grid.picture(e1,x=5/6,y=0.75,width=1,height=0.45)      
      grid.picture(e2,x=5/6,y=0.25,width=1,height=0.45)
      
      text(-0.05,1.01,'(a)',pos=4,cex=2)
      text(0.675,1.01,'(b)',pos=4,cex=2)
      text(0.675,0.48,'(c)',pos=4,cex=2)
      
      text(0.34,0.98,'Target only',adj=0.5,cex=1.5)
      text(0.168,0.63,'Monocular mask',adj=0.5,cex=1.5)
      text(0.52,0.63,'Dichoptic mask',adj=0.5,cex=1.5)
      text(0.166,0.28,'Aligned surround',adj=0.5,cex=1.5)
      text(0.52,0.28,'Orthogonal surround',adj=0.5,cex=1.5)
      
      text(0.26,0.93,'Left eye',adj=0.5,cex=1)
      text(0.42,0.93,'Right eye',adj=0.5,cex=1)
      text(0.086,0.58,'Left eye',adj=0.5,cex=1)
      text(0.248,0.58,'Right eye',adj=0.5,cex=1)
      text(0.438,0.58,'Left eye',adj=0.5,cex=1)
      text(0.602,0.58,'Right eye',adj=0.5,cex=1)
      text(0.086,0.23,'Left eye',adj=0.5,cex=1)
      text(0.248,0.23,'Right eye',adj=0.5,cex=1)
      text(0.438,0.23,'Left eye',adj=0.5,cex=1)
      text(0.602,0.23,'Right eye',adj=0.5,cex=1)
      
      points(0.25,0.982,pch=21,lwd=3,cex=2.5,bg=colourlist[1])
      points(0.04,0.63,pch=22,lwd=3,cex=2.5,bg=colourlist[2])
      points(0.4,0.63,pch=23,lwd=3,cex=2.5,bg=colourlist[3])
      points(0.03,0.28,pch=24,lwd=3,cex=2.5,bg=colourlist[4])
      points(0.36,0.28,pch=25,lwd=3,cex=2.5,bg=colourlist[5])
      
  dev.off()
  
file.remove(c('temp/saturationplot.ps','temp/CGvsRGexample.ps'))
file.remove(c('saturationplot.ps.xml','CGvsRGexample.ps.xml'))

}

```

```{r stimfig, fig.cap="Example stimuli and illustration of contrast response functions. Panel (a) shows five stimulus arrangments, illustrating how a vertical target pattern can be combined with four different mask types. Panel (b) shows three varieties of contrast response function, that either continue to accelerate (solid line), saturate (dashed line) or super-saturate (dotted line) across the range of displayable stimulus contrasts. Panel (c) illustrates a contrast gain (dashed line) and a response gain (dotted line) shift, relative to a baseline response (solid line).", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/stimfig.pdf')

```

An important distinction concerns whether a suppressive effect modulates the contrast gain or the response gain of a neuron (or neural population). Changes in contrast gain shift the stimulus-response curve (the contrast response function) laterally, whereas changes in response gain scale the function vertically (see examples in Figure \@ref(fig:stimfig)c). These different patterns may be indicative of specific neurophysiological underpinnings for an effect, and potentially different processes might occur at successive stages of processing. Previous studies have found that spatial attention modulates response gain [@Itthipuripat2019], whereas suppression from overlaid masks is more consistent with contrast gain [@Tsai2012]. Spatial adaptation appears to affect both contrast and response gain in primary visual cortex [@Albrecht1984], whereas motion adaptation is mostly attributable to contrast gain in area MT [@Kohn2003]. In addition, there is evidence that suppression builds up at successive stages of cortical processing, beyond primary visual cortex, and is stronger at later levels in the visual hierarchy [@Zenger-Landolt2003]. This is especially likely for surround suppression, which might be mediated by higher-level neurons with large receptive fields.

Neural responses can be measured non-invasively using steady-state visual evoked potentials [SSVEPs; @Norcia2015] recorded with either electroencephalography (EEG) or magnetoencephalography (MEG). By flickering the target stimulus at a fixed frequency, entrained neural oscillations are evoked at the flicker frequency, and also its higher harmonics (integer multiples of the flicker rate). Previous studies have shown that contrast-response functions measured using SSVEP are strongly modulated by overlaid masks [@Busse2009; @Tsai2012; @Baker2014], dichoptic masks [@Baker2017; @Chadnova2018], and surround masks [@Xiao2010; @Vanegas2015; @Benjamin2018].

We begin by conducting a computational re-analysis of 15 published studies to determine whether each type of suppression is best described as a contrast gain or a response gain effect. We then report results from two new SSVEP experiments to directly compare four mask types using a common paradigm. This also allowed us to explore changes across different electrode sites and different response frequencies. A secondary aim was to determine whether suppressive signals saturate as a function of contrast. We conducted the main experiment with two different mask contrasts, and analyse the data using a hierarchical Bayesian modelling approach.

# Methods

## Computational meta-analysis

### Inclusion criteria

Studies were included if they reported steady-state contrast response functions measured in human adults with no known disorders. Responses at 3 or more target contrasts were required to fit the baseline functions. We also required that a mask stimulus was presented in at least one condition. This could either be overlaid, dichoptic (presented to the opposite eye from a monocular target), or surrounding the target. We divided the surround conditions into those where the surround was aligned with (parallel to) the target, and those where it was orthogonal. For the overlay and dichoptic conditions, some studies used gratings and others used noise stimuli. Where multiple masking conditions were reported, we included data at the lowest mask contrast tested, and used data with orthogonal masks in preference to aligned masks (for overlay and dichoptic conditions). In studies where an experimental manipulation was carried out, we used data from the baseline (pre-manipulation) condition. We searched online databases using search terms including _SSVEP_, _steady-state_, _dichoptic_, _surround_, _mask_ and _suppression_, and applied the above criteria, resulting in 15 studies for inclusion in the analysis.

### Analysis and modelling

Contrast response function data were extracted using a computer program (WebPlotDigitizer 4.0.0) from the figures in each paper. Where necessary, these were converted to signal-to-noise ratios by dividing by the response to a blank screen, or at adjacent frequency bins to the target, or to the lowest target contrast condition. In some cases, results were averaged across different temporal frequency conditions to provide a single data set for each study.

Our primary objective was to understand the relative contributions of contrast gain and response gain to suppression from different mask types. We quantified this using a two-stage modelling approach. At the first stage, we fitted a standard gain control model [@Heeger1992] with three free parameters to the baseline data using a downhill simplex algorithm. The model is defined as:

\begin{equation}
\label{eq:GC1}
resp = R_{max}\frac{C^p}{Z + C^2} + 1,
\end{equation}

where _C_ is the target contrast. The $Z$ parameter sets the horizontal position of the response curve, $p$ governs the function shape (see Figure \@ref(fig:stimfig)b) from accelerating (_p_ > 2) to saturating (_p_ = 2) to super-saturating (_p_ < 2), and $R_{max}$ scales the overall height of the function. The additive constant (+1) represents additive noise, and converts the model response to a signal-to-noise ratio (implicitly, we also divide _resp_ by 1, but this is omitted as it has no effect). We fitted the model independently to each study's baseline data by minimising the root-mean-squared error between model and data.

The second stage of fitting used the parameter estimates from the first stage, and fitted the responses in the presence of a mask using the equation:

\begin{equation}
\label{eq:GC2}
resp = \frac{R_{max}}{r} \times \frac{C^p}{gZ + C^2} + 1,
\end{equation}

where the new terms _r_ and _g_ are free parameters that govern the extent of response gain and contrast gain, respectively. Values of _r_, _g_ > 1 indicate suppression, though in principle masks can also cause facilitation (_r_, _g_ < 1). We estimated values of these parameters jointly using the data from all studies (separately for each mask type) in a hierarchical Bayesian model. We defined broad hyperpriors for _g_ and _r_ as gamma distributions, with parameters $\alpha$ = 1.5, $\beta$ = 0.5. These functions peak at $\frac{\alpha-1}{\beta}$ = 1, so the prior expectation before observing any data is that there is no suppression of either kind. The priors had greater probability mass at values > 1, reflecting our expectation that one or both parameters would produce suppression, but also extended below 1, ensuring that the model was capable of capturing facilitation where it appeared in the data. Both parameters were constrained to have positive values. Bayesian modelling was implemented in _Stan_ [@Carpenter2017], based on an example script for hierarchical nonlinear regression accompanying Chapter 17 of @Kruschke2014. We examined how the posterior distribution of each parameter varied with mask type, both for individual studies, and across the whole sample.

## EEG experiments

### Participants

Twelve participants completed each version of the experiment (3 participants completed both experiments, the remaining 9 were unique to each experiment). All participants had normal or corrected-to-normal vision, and no known visual abnormalities. Participants were briefed on the experimental protocols and purpose, and provided written informed consent. The study was approved by the Department of Psychology Ethics Committee at the University of York.

### Apparatus and stimuli

Stimuli were presented using a ViewPixx 3D display (VPixx Technologies Inc., Quebec, Canada), driven by a Mac Pro computer. The refresh rate was 120 Hz, and we interleaved frames intended for the left and right eyes (60 Hz refresh rate per eye). To enable stereo presentation, the display update was synchronised with a set of NVidia 3D pro active shutter glasses using an infra-red signal. The display had a resolution of 1920 $\times$ 1280 pixels, and was viewed from a distance of 57cm, at which one degree of visual angle had a diameter of 36 pixels. To ensure good contrast resolution, the display was run in the high bit-depth monochrome M16 mode, which provided 16 bits of greyscale resolution. A Minolta LS110 photometer was used to gamma correct the display, which had a maximum luminance of 102 $cd/m^2$.

All stimuli were patches of sinusoidal grating with a spatial frequency of 1 cycle per degree. Target stimuli were randomly oriented on each trial, and windowed by a raised cosine envelope with a width of 2 degrees. There were 20 targets arranged in a symmetrical pattern around a central fixation marker, as shown in Figure \@ref(fig:stimfig)a. The target eccentricities were 3.6, 7.1, 8.5 and 10.7 degrees from the central fixation. Stimuli were spaced in 90 degree intervals at each radius, or in 45 degree intervals at the largest eccentricity. All target stimuli flickered sinusoidally at 5Hz (on-off flicker), between 0% contrast and their nominal Michelson contrast, which was one of six values (0, 6, 12, 24, 48 and 96%). Percentage Michelson contrast is defined as $100\frac{L_{max}-L_{min}}{L_{max}+L_{min}}$, where _L_ is luminance. Targets were shown to one eye only, which was chosen randomly on each trial. A binocular fixation marker was created from a cluster of overlaid squares (each 13 arc min wide) with random grey levels, designed to aid binocular fusion. Similar markers were also presented in the four corners of the stimulus region, at a distance of 15.7 degrees from the display centre.

We measured target responses with no mask, and also with four categories of mask stimulus. Monocular masks were shown to the same eye as the targets and in the same locations, but had orthogonal orientation. Dichoptic masks were the same, but shown to the non-target eye. Aligned surround masks were large (28 degrees in diameter) grating patches with the same orientation as the target, and with holes surrounding each target element (and the fixation marker). The holes were 4 degrees in diameter, meaning the gap between target and mask was 1 degree (one cycle of the stimulus waveform). Orthogonal surrounds were the same, but were oriented at 90 degrees relative to the targets. Both surround masks were presented to the target eye. There were two principal mask contrasts that were used in the two versions of the experiment: 12% and 24%. We also tested several additional mask contrasts (6, 48 and 96% contrast) for a single target contrast of 24%. The masks drifted at a speed of 6 deg/sec so that the phase alignment between mask and target changed over time [@Xiao2010]. Note that drifting gratings do not produce a steady-state signal, so we did not record responses to the mask stimuli. In addition, for some of the monocular mask conditions, the target contrast was reduced from 96% to 88% or 68% contrast to avoid clipping artifacts caused by overlaying the target and mask.

EEG activity was recorded using a 64-channel ANT Neuroscan system sampling at 1 kHz. Participants wore Waveguard caps, with electrodes organised according to the 10/20 system. The ground was located at position _AFz_, and each channel was referenced to the whole-head average. Electrode impedance was maintained at or below 5 k$\Omega$ throughout the experiment. Digital parallel triggers were sent from the ViewPixx display to the EEG amplifier, and recorded the onset of each trial on the EEG trace. Data were amplified, digitised, and saved to disc for offline analysis.

### Procedure

After providing consent, participants were set up with an EEG cap of appropriate size. They then completed six blocks, each comprising a full repetition of the experiment. Blocks lasted around 10 minutes, with the opportunity to take breaks between blocks. Within each block, all 42 conditions were repeated once in a randomized order. Trials lasted 11 seconds, with an inter-trial interval of 3 seconds. Participants were asked to monitor the central fixation and, as far as possible, to minimise blinking when a stimulus was displayed. To maintain attention, the central fixation marker was changed occasionally by re-randomizing the positions and luminances of the squares. There was a 50% chance of this happening on each trial. Participants were asked to count the number of times the fixation marker changed, and report this at the end of the block.

### Data analysis and modelling

All data were converted from the native ANT-EEProbe format to a compressed comma-separated value (csv) text file using a custom _Matlab_ script and components of the EEGlab toolbox [@Delorme2004]. The data for each participant were then loaded into _R_ for analysis. A ten-second waveform for each trial at each electrode was extracted, omitting the first one second after stimulus onset to avoid transients. The fast Fourier transform was calculated for each waveform, and the spectrum stored in a matrix. All repetitions of each condition were then coherently averaged (i.e. taking both the phase and amplitude into account), before being converted to a signal-to-noise ratio by dividing the amplitude at each frequency by the mean amplitude of the neighbouring 10 bins ($\pm0.5$ Hz in steps of 0.1 Hz). The signal-to-noise ratio at the target flicker frequency (5 Hz) and its second harmonic (10 Hz) were then used as dependent variables for further analysis.

We modelled the data using a two-stage Bayesian hierarchical model similar to that described above for the computational meta-analysis. Here, participant was the unit of observation instead of study. The other main difference was that we also used a hierarchical model (instead of simplex fitting) at the first stage to fit the parameters of the baseline contrast response function (_Z_, _p_ and $R_{max}$). This seemed appropriate for our novel data set, given that all participants viewed the same stimuli, whereas in the computational meta-analysis different studies had different stimulus parameters. The hyperpriors for each parameter were normal distributions with parameters: $\mu$ = 100, $\sigma$ = 40 (_Z_); $\mu$ = 2, $\sigma$ = 0.25 (_p_); and $\mu$ = 5, $\sigma$ = 2 ($R_{max}$). All parameters were constrained to have positive values. Again, we were most interested in the posterior distributions of the suppression parameters (_r_ and _g_), and explored how these varied by mask type, electrode position, and response frequency.

## Data and script availability

All data and scripts are publicly available at: [https://osf.io/e62wu/](https://osf.io/e62wu/)

# Results

## Previous studies do not sufficiently distinguish contrast vs response gain

We began by conducting a computational meta-analysis of 15 SSVEP studies from the literature [@Baker2014; @Burr1987; @Busse2009; @Candy2001; @Ross1991; @Smith2017; @Tsai2012; @Baker2015; @Baker2017; @Chadnova2018; @Hou2020; @Zhou2015; @Benjamin2018; @Vanegas2015; @Vanegas2019]. Study-specific information is given in Table \@ref(tab:metatable) and the results are shown in Figure \@ref(fig:metaanalysis). For each study, we replot the contrast response functions for the target alone (black points), and with the mask present (coloured points), along with model fits (curves). The model described the data well. The kernel density functions show posterior distributions of parameters for the response gain parameter (_r_, grey distributions), and the contrast gain parameter (_g_, coloured distributions). For each mask type, the vertical dashed line indicates no suppression (a weight of 1). The 95% highest density intervals are given by the horizontal bars - where these overlap 1 we lack credible evidence for that type of suppression.

```{r metatable, echo=FALSE}

tabledata <- read.csv('temp/MAtable.csv')
tabledata <- tabledata[,1:8]
tabledata[,8] <- round(tabledata[,8],digits=2)

colnames(tabledata) <- c('Study','Method','N','Target','TF (Hz)', 'Mask', 'Location','SI')
kable(tabledata, caption = 'Table summarising methodological details for each study in the meta analysis. N: number of participants, SI: saturation index.') 

```

For individual studies, we see some credible evidence for contrast gain (8 data sets) and response gain (4 data sets), but a consistent pattern does not emerge. For the group posterior distributions given at the foot of each panel, all of the 95% highest density intervals overlap 1. This suggests that overall the literature does not give a consistent picture of whether response gain or contrast gain is responsible for each type of suppression (though the mean weights for contrast gain are much higher on average). This could be for any number of reasons, but is likely to be partly due to the methodological heterogeneity across studies (see Table \@ref(tab:metatable)). To address this shortcoming, we conducted a new study in which participants viewed stimuli involving all four types of mask.

```{r include=FALSE}

# create Figure 2 - meta analysis of 15 studies
if (runcode==1){
  
  nchains <- 30000    # total number of MCMC chains
  rsigcount <- 0
  gsigcount <- 0
  
  conditionnames <- c('Overlay','Dichoptic','Aligned surround', 'Orthogonal surround')  
  vertsize <- c(8,8,4,4)
  
  options(mc.cores=3)
  
  fitbaseline <- function(p){
    p <- 10^p
    model <- 1 + p[3]*(Cvals^p[2])/(p[1] + Cvals^2)
    rms <- sqrt(mean((model-yvals)^2))
    return(rms)}  
  
  # second model definition sets up a hierarchical model that fits two parameters - r and g, to modulate response gain and contrast gain
  genMCMC2 = function(data, xName="C", yName="y", sName="s", fixedparams=NULL, wName=NULL, numSavedSteps=10000, thinSteps = 1, saveName=NULL){ 
    require(rstan)
    #-----------------------------------------------------------------------------
    # THE DATA.
    y = data[,yName]
    x = data[,xName]
    s = as.numeric(data[,sName])
    if ( !is.null(wName) ) {
      w = data[,wName]
    } else {
      w = rep(1,length(y))
    }
    Zvals = fixedparams[,1]
    pvals = fixedparams[,2]
    Rvals = fixedparams[,3]
    
    # Do some checking that data make sense:
    if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
    if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
    #Ntotal = length(y)
    # Specify the data in a list, for later shipment to JAGS:
    dataList = list(
      x = x ,
      y = y ,
      s = s ,
      w = w ,
      Zvals = Zvals ,
      pvals = pvals ,
      Rvals = Rvals ,
      Nsubj = max(s)  , # should equal length(unique(s))
      Ntotal = length(y)
    )
    #-----------------------------------------------------------------------------
    # THE MODEL.
    
    modelString = "
  data {
    int<lower=1> Nsubj ;
    int<lower=1> Ntotal ;
    real y[Ntotal] ;
    real x[Ntotal] ;
    real<lower=0> w[Ntotal] ;
    int<lower=1> s[Ntotal] ;
    real<lower=0> Zvals[Nsubj] ;
    real<lower=0> pvals[Nsubj] ;
    real<lower=0> Rvals[Nsubj] ;
  }
  parameters {
    real<lower=0> r[Nsubj] ;
    real<lower=0> g[Nsubj] ;
    real<lower=0> sigma ;
    real<lower=0> rmu ; 
    real<lower=0> gmu ; 
    real<lower=0> rsigma ;
    real<lower=0> gsigma ;
    real<lower=0> nu ;
  }
  model {
    rmu ~ gamma( 1.5 , 0.5 ) ;
    gmu ~ gamma( 1.5 , 0.5 ) ;
    sigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    rsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    gsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    nu ~ exponential(1/30.0) ;
    r ~ normal( rmu , rsigma ) ; // vectorized
    g ~ normal( gmu , gsigma ) ; // vectorized
    for ( i in 1:Ntotal ) {
      y[i] ~ student_t( 
                nu ,
                1 + (Rvals[s[i]]/r[s[i]])*(pow(x[i],pvals[s[i]]))/(g[s[i]]*Zvals[s[i]] + square(x[i])) ,
                w[i]*sigma ) ;
    }
  }  
  " # close quote for modelString
    
    # Write out modelString to a text file
    writeLines( modelString , con="TEMPmodel.txt" )
    #-----------------------------------------------------------------------------
    # INTIALIZE THE CHAINS.
    
    # Use lm() to find reasonable coefficients overall, then start all individual
    # units and overall at those values.
    # N.B. THIS DOES NOT ALWAYS WORK AND DOES NOT ALWAYS IMPROVE THE MCMC SAMPLE.
    # IF IT'S A PROBLEM, COMMENT OUT THE inits ARGUMENT IN THE run.jags COMMAND.
    rinit = 1
    ginit = 1
    sigmaInit = 1
    nuInit = 10 # arbitrary
    initsList = list(
      sigma=sigmaInit  ,
      nu=nuInit ,
      rmu=rinit ,
      gmu=ginit ,
      r=rep(rinit,max(s)) ,
      g=rep(ginit,max(s))  # other params filled in by JAGS
    )
    
    #-----------------------------------------------------------------------------
    # RUN THE CHAINS
    parameters = c( "r" ,  "g" ,
                    "rmu" , "gmu" ,
                    "sigma" , "nu")
    adaptSteps = 1000  # Number of steps to "tune" the samplers
    burnInSteps = 2000 
    nChains = 3 
    
    # Translate to C++ and compile to DSO:
    stanDso <- stan_model( model_code=modelString ) 
    # Get MC sample of posterior:
    stanFit <- sampling( object=stanDso , 
                         data = dataList , 
                         #pars = parameters , # optional
                         #init = initsList , # optional  
                         chains = nChains ,
                         iter = ( ceiling(numSavedSteps/nChains)*thinSteps
                                  +burnInSteps ) , 
                         warmup = burnInSteps , 
                         thin = thinSteps,
                         cores = getOption("mc.cores", 1L))
    # For consistency with JAGS-oriented functions in DBDA2E collection, 
    # convert stan format to coda format:
    codaSamples = mcmc.list( lapply( 1:ncol(stanFit) , 
                                     function(x) { mcmc(as.array(stanFit)[,x,]) } ) )
    # resulting codaSamples object has these indices: 
    #   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]
    if ( !is.null(saveName) ) {
      save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
      save( stanFit , file=paste(saveName,"StanFit.Rdata",sep="") )
      save( stanDso , file=paste(saveName,"StanDso.Rdata",sep="") )
    }  
    
    return( codaSamples )
  }
  
  metdata <- read.csv('temp/MAdata.csv')
  condnames <- levels(metdata$Mask)
  condnames <- condnames[c(2,1,3,4)]
  
  pdf(paste('figures/metaanalysis.pdf',sep=''), bg="transparent", height = 10, width = 10)
  # par(mfrow=c(2,2), mar=c(2,3,2,1))
  layout(matrix(c(1,3,2,4),2,2),c(1,1),c(8,5))
  
  for (cond in 1:4){  
    
    thiscond <- droplevels(subset(metdata, Mask==condnames[cond]))
    studynames <- levels(thiscond$Study)
    nstudies <- nlevels(thiscond$Study)
    
    bl <- droplevels(subset(thiscond, Condition==1, select=c('Study','Contrast','SNR')))
    colnames(bl) <- c('s','C','y')
    bl$s <- as.numeric(bl$s)
    
    paramlist <- matrix(0,nrow=nstudies,ncol=5)
    for (s in 1:nstudies){
      i <- which(bl$s==s)
      Cvals <<- bl$C[i]
      yvals <<- bl$y[i]
      sout <- fminsearch(fitbaseline,log10(c(100,2,4)))
      paramlist[s,1:3] <- 10^sout$optbase$xopt
    }
    
    mm <- droplevels(subset(thiscond, Condition==2, select=c('Study','Contrast','SNR')))
    colnames(mm) <- c('s','C','y')
    mm$s <- as.numeric(mm$s)
    
    mcmcCoda2 <- genMCMC2(mm,xName='C',yName='y',sName='s',fixedparams=paramlist,numSavedSteps=nchains)
    
    groupr <- NULL
    groupg <- NULL
    for (i in 1:length(mcmcCoda2)){
      groupr <- c(groupr,mcmcCoda2[[i]][,(2*nstudies)+2])
      groupg <- c(groupg,mcmcCoda2[[i]][,(2*nstudies)+3])  
    }
    
    studyr <- matrix(0,nrow=nstudies,ncol=nchains)
    studyg <- matrix(0,nrow=nstudies,ncol=nchains)
    for (s in 1:nstudies){
      allr <- NULL
      allg <- NULL
      for (i in 1:length(mcmcCoda2)){
        allr <- c(allr,mcmcCoda2[[i]][,s])
        allg <- c(allg,mcmcCoda2[[i]][,s+nstudies])
      }
      studyr[s,] <- allr
      studyg[s,] <- allg
      paramlist[s,4:5] <- c(mean(allr),mean(allg))
    }
    
    
    plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(0,3), ylim=c(0,vertsize[cond]))
    title(main=conditionnames[cond])
    
    finecontsC <- 10^((-14:40)/20)
    for (n in 1:nstudies){
      text(0,vertsize[cond]+0.2-n,studynames[n],pos=4)
      lines(c(0.8,1.8),vertsize[cond]-c(n,n))
      lines(c(2,3),vertsize[cond]-c(n,n))}
    lines(c(2,3),c(0,0))
    
    for (n in 1:nstudies){
      tofit <- droplevels(subset(thiscond, Study==studynames[n]))
      
      baseline <- subset(tofit, Condition==1, select = c('Contrast','SNR'))
      mask <- subset(tofit, Condition==2, select = c('Contrast','SNR'))
      
      baseline$Contrast[which(baseline$Contrast==0)] <- 0.2
      mask$Contrast[which(mask$Contrast==0)] <- 0.2
      baseline$SNR <- baseline$SNR-1
      mask$SNR <- mask$SNR-1
      xvals <- 0.8+(14+20*log10(baseline$Contrast))/54
      yvals <- (vertsize[cond]-n)+0.8*(baseline$SNR/max(baseline$SNR))
      points(xvals,yvals,pch=16)
      
      blmod <- paramlist[n,3]*(finecontsC^paramlist[n,2])/(paramlist[n,1] + finecontsC^2)
      xvalsmod <- 0.8+(14+20*log10(finecontsC))/54
      yvalsmod <- (vertsize[cond]-n)+0.8*(blmod/max(baseline$SNR))
      lines(xvalsmod,yvalsmod,col=colourlist[1])
      
      xvals <- 0.8+(14+20*log10(mask$Contrast))/54
      yvals <- (vertsize[cond]-n)+0.8*(mask$SNR/max(baseline$SNR))
      points(xvals,yvals,pch=16,col=colourlist[cond+1])
      
      mmod <- (paramlist[n,3]/paramlist[n,4])*(finecontsC^paramlist[n,2])/(paramlist[n,5]*paramlist[n,1] + finecontsC^2)
      yvalsmod <- (vertsize[cond]-n)+0.8*(mmod/max(baseline$SNR))
      lines(xvalsmod,yvalsmod,col=colourlist[cond+1])    
      
      a <- density(studyr[n,],from=0,to=15)
      b <- density(studyg[n,],from=0,to=15)
      kernx <- c(0,a$x,15)
      kerny <- c(0,a$y,0)
      kernx <- 2 + (kernx/15)
      kerny <- (vertsize[cond]-n)+0.8*(kerny/max(kerny))
      polygon(kernx,kerny,col=addalpha('black',0.5),border=NA)
      
      kernx <- c(0,b$x,15)
      kerny <- c(0,b$y,0)
      kernx <- 2 + (kernx/15)
      kerny <- (vertsize[cond]-n)+0.8*(kerny/max(kerny))
      polygon(kernx,kerny,col=addalpha(colourlist[cond+1],0.5),border=NA)  
      
      ci <- hdi(studyr[n,],ci=hdirange)
      yplace <- (vertsize[cond]-n)+0.6
      if (ci$CI_high<15){
        arrows(2+(ci$CI_low/15),yplace, x1=2+(ci$CI_high/15), y1=yplace,length=0.015, angle=90, lwd=2)
        arrows(2+(ci$CI_high/15),yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2)}
      if (ci$CI_high>15){
        arrows(2+(ci$CI_low/15),yplace, x1=3, y1=yplace,length=0.015, angle=45, lwd=2)
        arrows(3,yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2)}
      
      
      if (ci$CI_low>1){rsigcount <- rsigcount + 1}
      
      ci <- hdi(studyg[n,],ci=hdirange)
      yplace <- (vertsize[cond]-n)+0.3
      if (ci$CI_high<15){
        arrows(2+(ci$CI_low/15),yplace, x1=2+(ci$CI_high/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])
        arrows(2+(ci$CI_high/15),yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])}
      if (ci$CI_high>15){
        arrows(2+(ci$CI_low/15),yplace, x1=3, y1=yplace,length=0.015, angle=45, lwd=2,col=colourlist[cond+1])
        arrows(3,yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])}
      
      
      if (ci$CI_low>1){gsigcount <- gsigcount + 1}
      
    }
    
    text(0.8,0.2,'Group posterior',pos=4)
    
    a <- density(groupr,from=0,to=15)
    b <- density(groupg,from=0,to=15)
    kernx <- c(0,a$x,15)
    kerny <- c(0,a$y,0)
    kernx <- 2 + (kernx/15)
    kerny <- 0.8*(kerny/max(kerny))
    polygon(kernx,kerny,col=addalpha('black',0.5),border=NA)
    kernx <- c(0,b$x,15)
    kerny <- c(0,b$y,0)
    kernx <- 2 + (kernx/15)
    kerny <- 0.8*(kerny/max(kerny))
    polygon(kernx,kerny,col=addalpha(colourlist[cond+1],0.5),border=NA)  
    
    ci <- hdi(groupr,ci=hdirange)
    yplace <- 0.6
    if (ci$CI_high<15){
      arrows(2+(ci$CI_low/15),yplace, x1=2+(ci$CI_high/15), y1=yplace,length=0.015, angle=90, lwd=2)
      arrows(2+(ci$CI_high/15),yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2)}
    if (ci$CI_high>15){
      arrows(2+(ci$CI_low/15),yplace, x1=3, y1=yplace,length=0.015, angle=45, lwd=2)
      arrows(3,yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2)}
    
    
    ci <- hdi(groupg,ci=hdirange)
    yplace <- 0.3
    if (ci$CI_high<15){
      arrows(2+(ci$CI_low/15),yplace, x1=2+(ci$CI_high/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])
      arrows(2+(ci$CI_high/15),yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])}
    if (ci$CI_high>15){
      arrows(2+(ci$CI_low/15),yplace, x1=3, y1=yplace,length=0.015, angle=45, lwd=2,col=colourlist[cond+1])
      arrows(3,yplace, x1=2+(ci$CI_low/15), y1=yplace,length=0.015, angle=90, lwd=2,col=colourlist[cond+1])}
    
    lines(c(2,2)+(1/15),c(0,vertsize[cond]),lty=2)
    
  }
  
  dev.off()
  
}

```

```{r metaanalysis, fig.cap="Computational meta-analysis of 15 studies from the literature reporting SSVEP measures of suppression. Each study is referred to by the first author surname - see text for full citations. Contrast response functions at baseline (black points) and with a mask present (coloured points) were fit using a two stage modelling procedure (curves). The posterior distributions (vertically rescaled for visibility) of parameter estimates for response gain (grey) and contrast gain (colours) are shown for each study and the group estimates. Vertical dashed lines indicate a parameter value of 1 (the axis extends to x = 15). Horizontal bars give the 95 percent highest density intervals for each parameter estimate.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/metaanalysis.pdf')

```

## Suppression is due to contrast gain at the first harmonic for all mask types

```{r include=FALSE}

# load in data and calculate SNRs
if (runcode==1){
  if (processraw==1){
    # the code here does the primary SSVEP analysis from the raw data. This takes a long time (around 2 hours), and the results are saved in the RData file for faster loading
    tic()
    
    allspeclow <- array(0,dim = c(12,5,9,64,duration*20))
    for (s in 1:12){
      d <- dir(path=paste('~/Desktop/SurroundEEG/S',s,'low/',sep=''),pattern='*.csv.gz')
      
      allspec <- array(0,dim = c(6,5,9,64,duration*20))
      condcounter <- matrix(0,nrow=5,ncol=9)
      for (block in 1:length(d)){
        EEGdata <- read.csv(paste('~/Desktop/SurroundEEG/S',s,'low/',d[block],sep=''),header=TRUE)
        
        electrodes <- colnames(EEGdata)
        
        # epoch the data, Fourier transform and store
        triggertimes <- NULL
        counter <- 0
        for (n in 1:nrow(EEGdata)){
          if(EEGdata$Trigger[n] %in% legaltriggers){
            counter <- counter + 1
            triggertimes[counter] <- n
          }
        }
        
        for (tr in 1:counter){
          cond <- EEGdata$Trigger[triggertimes[tr]]%/%10
          level <- EEGdata$Trigger[triggertimes[tr]]%%10
          condcounter[cond,level] <- condcounter[cond,level] + 1
          for (ch in 1:64){
            sample <- EEGdata[(triggertimes[tr]):(triggertimes[tr]+samplerate*duration),ch+2]
            fftsample <- fft(sample)/(samplerate*duration)
            
            allspec[condcounter[cond,level],cond,level,ch,] <- fftsample[1:(duration*20)]
          }}
      }
      allspeclow[s,,,,] <- apply(allspec,c(2,3,4,5),mean,na.rm=TRUE)
    }
    
    allspechi <- array(0,dim = c(12,5,9,64,duration*20))
    for (s in 1:12){
      d <- dir(path=paste('~/Desktop/SurroundEEG/S',s,'high/',sep=''),pattern='*.csv.gz')
      
      allspec <- array(0,dim = c(6,5,9,64,duration*20))
      condcounter <- matrix(0,nrow=5,ncol=9)
      for (block in 1:length(d)){
        EEGdata <- read.csv(paste('~/Desktop/SurroundEEG/S',s,'high/',d[block],sep=''),header=TRUE)
        
        electrodes <- colnames(EEGdata)
        
        # epoch the data, Fourier transform and store
        triggertimes <- NULL
        counter <- 0
        for (n in 1:nrow(EEGdata)){
          if(EEGdata$Trigger[n] %in% legaltriggers){
            counter <- counter + 1
            triggertimes[counter] <- n
          }
        }
        
        for (tr in 1:counter){
          cond <- EEGdata$Trigger[triggertimes[tr]]%/%10
          level <- EEGdata$Trigger[triggertimes[tr]]%%10
          condcounter[cond,level] <- condcounter[cond,level] + 1
          for (ch in 1:64){
            sample <- EEGdata[(triggertimes[tr]):(triggertimes[tr]+samplerate*duration),ch+2]
            fftsample <- fft(sample)/(samplerate*duration)
            
            allspec[condcounter[cond,level],cond,level,ch,] <- fftsample[1:(duration*20)]
          }}
      }
      allspechi[s,,,,] <- apply(allspec,c(2,3,4,5),mean,na.rm=TRUE)
    }
    
    save(list=c('allspeclow','allspechi','electrodes'),file='temp/SSVEPdata.RData')
    
    toc()  
  }
  
  load('temp/SSVEPdata.RData')
  allspechi[which(allspechi==0)] <- 0.0001     # fiddle to avoid NaN issues in the SNR
  allspeclow[which(allspeclow==0)] <- 0.0001

  meanspeclow <- apply(abs(allspeclow),c(2,3,4,5),mean,na.rm=TRUE)
  meanspechi <- apply(abs(allspechi),c(2,3,4,5),mean,na.rm=TRUE)
  
  meanphaselow <- (apply(Arg(allspeclow),c(2,3,4,5),mean,na.rm=TRUE))
  meanphasehi <- (apply(Arg(allspechi),c(2,3,4,5),mean,na.rm=TRUE))
  
  # calculate SNR by dividing by activity in adjacent bins
  allSNRlow <- array(0,dim=c(12,5,9,64,200))
  allSNRhi <- array(0,dim=c(12,5,9,64,200))

  for (s in 1:12){
    for (cond in 1:5){
      for (level in 1:9){
        for (ch in 1:64){
          for (f in 6:194){
            allSNRlow[s,cond,level,ch,f] <- abs(allspeclow[s,cond,level,ch,f])/mean(abs(allspeclow[s,cond,level,ch,f+c(-5:-1,1:5)]))
            allSNRhi[s,cond,level,ch,f] <- abs(allspechi[s,cond,level,ch,f])/mean(abs(allspechi[s,cond,level,ch,f+c(-5:-1,1:5)]))
            
          }}}}}
  
  meanSNRlow <- apply(allSNRlow,c(2,3,4,5),mean)
  meanSNRhi <- apply(allSNRhi,c(2,3,4,5),mean)
  seSNRlow <- apply(allSNRlow,c(2,3,4,5),sd)/sqrt(12)
  seSNRhi <- apply(allSNRhi,c(2,3,4,5),sd)/sqrt(12)
}


```
  
```{r include=FALSE, echo=FALSE, warning=FALSE, results='hide'}

# set up and run Stan models, save outputs
if (runmodels==1){
  
nchains <- 12000    # total number of MCMC chains (should be at least 10000)
options(mc.cores=3)
  
# first model definition sets up a hierarchical model that fits three parameters - Z, p and Rmax to fit the baseline data
genMCMC = function(data, xName="C", yName="y", sName="s", wName=NULL, numSavedSteps=10000, thinSteps = 1, saveName=NULL){ 
  require(rstan)
  #-----------------------------------------------------------------------------
  # THE DATA.
  y = data[,yName]
  x = data[,xName]
  s = as.numeric(data[,sName])
  if ( !is.null(wName) ) {
    w = data[,wName]
  } else {
    w = rep(1,length(y))
  }
  # Do some checking that data make sense:
  if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
  if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
  #Ntotal = length(y)
  # Specify the data in a list, for later shipment to JAGS:
  dataList = list(
    x = x ,
    y = y ,
    s = s ,
    w = w ,
    Nsubj = max(s)  , # should equal length(unique(s))
    Ntotal = length(y)
  )
  #-----------------------------------------------------------------------------
  # THE MODEL.
  
  modelString = "
  data {
    int<lower=1> Nsubj ;
    int<lower=1> Ntotal ;
    real y[Ntotal] ;
    real x[Ntotal] ;
    real<lower=0> w[Ntotal] ;
    int<lower=1> s[Ntotal] ;
  }
  parameters {
    real<lower=1> Z[Nsubj] ;
    real<lower=1> p[Nsubj] ;
    real<lower=0> Rmax[Nsubj] ;
    real<lower=0> sigma ;
    real<lower=1> Zmu ; 
    real<lower=1> pmu ; 
    real<lower=0> Rmaxmu ; 
    real<lower=0> Zsigma ;
    real<lower=0> psigma ;
    real<lower=0> Rmaxsigma ;
    real<lower=0> nu ;
  }
  model {
    Zmu ~ normal( 100 , 40 ) ;
    pmu ~ normal( 2 , 0.25 ) ;
    Rmaxmu ~ normal( 5 , 2 ) ;
    sigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    Zsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    psigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    Rmaxsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    nu ~ exponential(1/30.0) ;
    Z ~ normal( Zmu , Zsigma ) ; // vectorized
    p ~ normal( pmu , psigma ) ; // vectorized
    Rmax ~ normal( Rmaxmu , Rmaxsigma ) ; // vectorized
    for ( i in 1:Ntotal ) {
      y[i] ~ student_t( 
                nu ,
                1 + (Rmax[s[i]]*(pow(x[i],p[s[i]]))/(Z[s[i]] + square(x[i]))) ,
                w[i]*sigma ) ;
    }
  }  
  " # close quote for modelString
  
  # Write out modelString to a text file
  writeLines( modelString , con="TEMPmodel.txt" )
  #-----------------------------------------------------------------------------
  # INTIALIZE THE CHAINS.
  
  # Use lm() to find reasonable coefficients overall, then start all individual
  # units and overall at those values.
  # N.B. THIS DOES NOT ALWAYS WORK AND DOES NOT ALWAYS IMPROVE THE MCMC SAMPLE.
  # IF IT'S A PROBLEM, COMMENT OUT THE inits ARGUMENT IN THE run.jags COMMAND.
  Zinit = 50
  pinit = 2
  Rmaxinit = 5
  sigmaInit = 1
  nuInit = 10 # arbitrary
  initsList = list(
    sigma=sigmaInit  ,
    nu=nuInit ,
    Zmu=Zinit ,
    pmu=pinit ,
    Rmaxmu=Rmaxinit ,
    Z=rep(Zinit,max(s)) ,
    p=rep(pinit,max(s)) ,
    Rmax=rep(Rmaxinit,max(s)) # other params filled in by JAGS
  )
  
  #-----------------------------------------------------------------------------
  # RUN THE CHAINS
  parameters = c( "Z" ,  "p" ,  "Rmax" ,
                  "Zmu" , "pmu" , "Rmaxmu" ,
                  "sigma" , "nu")
  adaptSteps = 1000  # Number of steps to "tune" the samplers
  burnInSteps = 2000 
  nChains = 3 
  
  # Translate to C++ and compile to DSO:
  stanDso <- stan_model( model_code=modelString ) 
  # Get MC sample of posterior:
  stanFit <- sampling( object=stanDso , 
                       data = dataList , 
                       #pars = parameters , # optional
                       #init = initsList , # optional  
                       chains = nChains ,
                       iter = ( ceiling(numSavedSteps/nChains)*thinSteps
                                +burnInSteps ) , 
                       warmup = burnInSteps , 
                       thin = thinSteps,
                       cores = getOption("mc.cores", 1L))
  # For consistency with JAGS-oriented functions in DBDA2E collection, 
  # convert stan format to coda format:
  codaSamples = mcmc.list( lapply( 1:ncol(stanFit) , 
                                   function(x) { mcmc(as.array(stanFit)[,x,]) } ) )
  # resulting codaSamples object has these indices: 
  #   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]
  if ( !is.null(saveName) ) {
    save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
    save( stanFit , file=paste(saveName,"StanFit.Rdata",sep="") )
    save( stanDso , file=paste(saveName,"StanDso.Rdata",sep="") )
  }  
  
  return( codaSamples )
}

# second model definition sets up a hierarchical model that fits two parameters - r and g, to modulate response gain and contrast gain
genMCMC2 = function(data, xName="C", yName="y", sName="s", fixedparams=NULL, wName=NULL, numSavedSteps=10000, thinSteps = 1, saveName=NULL){ 
  require(rstan)
  #-----------------------------------------------------------------------------
  # THE DATA.
  y = data[,yName]
  x = data[,xName]
  s = as.numeric(data[,sName])
  if ( !is.null(wName) ) {
    w = data[,wName]
  } else {
    w = rep(1,length(y))
  }
  Zvals = fixedparams[,1]
  pvals = fixedparams[,2]
  Rvals = fixedparams[,3]
  
  # Do some checking that data make sense:
  if ( any( !is.finite(y) ) ) { stop("All y values must be finite.") }
  if ( any( !is.finite(x) ) ) { stop("All x values must be finite.") }
  #Ntotal = length(y)
  # Specify the data in a list, for later shipment to JAGS:
  dataList = list(
    x = x ,
    y = y ,
    s = s ,
    w = w ,
    Zvals = Zvals ,
    pvals = pvals ,
    Rvals = Rvals ,
    Nsubj = max(s)  , # should equal length(unique(s))
    Ntotal = length(y)
  )
  #-----------------------------------------------------------------------------
  # THE MODEL.
  
  modelString = "
  data {
    int<lower=1> Nsubj ;
    int<lower=1> Ntotal ;
    real y[Ntotal] ;
    real x[Ntotal] ;
    real<lower=0> w[Ntotal] ;
    int<lower=1> s[Ntotal] ;
    real<lower=0> Zvals[Nsubj] ;
    real<lower=0> pvals[Nsubj] ;
    real<lower=0> Rvals[Nsubj] ;
  }
  parameters {
    real<lower=0> r[Nsubj] ;
    real<lower=0> g[Nsubj] ;
    real<lower=0> sigma ;
    real<lower=0> rmu ; 
    real<lower=0> gmu ; 
    real<lower=0> rsigma ;
    real<lower=0> gsigma ;
    real<lower=0> nu ;
  }
  model {
    rmu ~ gamma( 1.5 , 0.5 ) ;
    gmu ~ gamma( 1.5 , 0.5 ) ;
    sigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    rsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    gsigma ~ uniform( 1.0E-3 , 1.0E+3 ) ;
    nu ~ exponential(1/30.0) ;
    r ~ normal( rmu , rsigma ) ; // vectorized
    g ~ normal( gmu , gsigma ) ; // vectorized
    for ( i in 1:Ntotal ) {
      y[i] ~ student_t( 
                nu ,
                1 + (Rvals[s[i]]/r[s[i]])*(pow(x[i],pvals[s[i]]))/(g[s[i]]*Zvals[s[i]] + square(x[i])) ,
                w[i]*sigma ) ;
    }
  }  
  " # close quote for modelString
  
  # Write out modelString to a text file
  writeLines( modelString , con="TEMPmodel.txt" )
  #-----------------------------------------------------------------------------
  # INTIALIZE THE CHAINS.
  
  # Use lm() to find reasonable coefficients overall, then start all individual
  # units and overall at those values.
  # N.B. THIS DOES NOT ALWAYS WORK AND DOES NOT ALWAYS IMPROVE THE MCMC SAMPLE.
  # IF IT'S A PROBLEM, COMMENT OUT THE inits ARGUMENT IN THE run.jags COMMAND.
  rinit = 1
  ginit = 1
  sigmaInit = 1
  nuInit = 10 # arbitrary
  initsList = list(
    sigma=sigmaInit  ,
    nu=nuInit ,
    rmu=rinit ,
    gmu=ginit ,
    r=rep(rinit,max(s)) ,
    g=rep(ginit,max(s))  # other params filled in by JAGS
  )
  
  #-----------------------------------------------------------------------------
  # RUN THE CHAINS
  parameters = c( "r" ,  "g" ,
                  "rmu" , "gmu" ,
                  "sigma" , "nu")
  adaptSteps = 1000  # Number of steps to "tune" the samplers
  burnInSteps = 2000 
  nChains = 3 
  
  # Translate to C++ and compile to DSO:
  stanDso <- stan_model( model_code=modelString ) 
  # Get MC sample of posterior:
  stanFit <- sampling( object=stanDso , 
                       data = dataList , 
                       #pars = parameters , # optional
                       #init = initsList , # optional  
                       chains = nChains ,
                       iter = ( ceiling(numSavedSteps/nChains)*thinSteps
                                +burnInSteps ) , 
                       warmup = burnInSteps , 
                       thin = thinSteps,
                       cores = getOption("mc.cores", 1L))
  # For consistency with JAGS-oriented functions in DBDA2E collection, 
  # convert stan format to coda format:
  codaSamples = mcmc.list( lapply( 1:ncol(stanFit) , 
                                   function(x) { mcmc(as.array(stanFit)[,x,]) } ) )
  # resulting codaSamples object has these indices: 
  #   codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]
  if ( !is.null(saveName) ) {
    save( codaSamples , file=paste(saveName,"Mcmc.Rdata",sep="") )
    save( stanFit , file=paste(saveName,"StanFit.Rdata",sep="") )
    save( stanDso , file=paste(saveName,"StanDso.Rdata",sep="") )
  }  
  
  return( codaSamples )
}


posteriorweights <- array(0,dim=c(2,64,8,2,nchains))
posteriorparams <- array(0,dim=c(2,64,6,nchains))

currentch <- 1
currentexpt <- 1
currentfreq <- 1
if (file.exists('temp/modelweights.RData')==1){load('temp/modelweights.RData')}

for (freq in currentfreq:2){
for (expt in currentexpt:2){
for (ch in currentch:64){
save(file=paste('temp/progressfileF',freq,'E',expt,'Ch',ch,'.Rdata',sep=''),list='ch')
  
tempcontrasts <- c(0,6,12,24,48,96)
if (expt==1){bl <- melt(abs(allSNRlow[,1,1:6,ch,tindex[freq]]))}
if (expt==2){bl <- melt(abs(allSNRhi[,1,1:6,ch,tindex[freq]]))}
colnames(bl) <- c('s','C','y')
bl[,'C'] <- tempcontrasts[bl[,'C']]

mcmcCoda <- genMCMC(bl,xName='C',yName='y',sName='s',numSavedSteps=nchains)

paramlist <- matrix(0,nrow=12,ncol=3)
for (s in 1:12){
  allZ <- NULL
  allp <- NULL
  allRmax <- NULL
  for (i in 1:length(mcmcCoda)){
  allZ <- c(allZ,mcmcCoda[[i]][,s])
  allp <- c(allp,mcmcCoda[[i]][,s+12])
  allRmax <- c(allRmax,mcmcCoda[[i]][,s+24])
  }
  paramlist[s,] <- c(mean(allZ),mean(allp),mean(allRmax))
}

  allZ <- NULL
  allp <- NULL
  allRmax <- NULL
  for (i in 1:length(mcmcCoda)){
  allZ <- c(allZ,mcmcCoda[[i]][,38])
  allp <- c(allp,mcmcCoda[[i]][,39])
  allRmax <- c(allRmax,mcmcCoda[[i]][,40])
  }

    posteriorparams[freq,ch,1+(expt-1)*3,] <- allZ
    posteriorparams[freq,ch,2+(expt-1)*3,] <- allp
    posteriorparams[freq,ch,3+(expt-1)*3,] <- allRmax

for (m in 1:4){
  
tempcontrasts <- c(6,12,24,48,96)
if (expt==1){if (m==1){tempcontrasts <- lowmonconts}}
if (expt==2){if (m==1){tempcontrasts <- himonconts}}  
    
if (expt==1){mm <- melt(abs(allSNRlow[,m+1,1:5,ch,tindex[freq]]))}
if (expt==2){mm <- melt(abs(allSNRhi[,m+1,1:5,ch,tindex[freq]]))}
   
colnames(mm) <- c('s','C','y')
mm[,'C'] <- tempcontrasts[mm[,'C']]

mcmcCoda2 <- genMCMC2(mm,xName='C',yName='y',sName='s',fixedparams=paramlist,numSavedSteps=nchains)

  allr <- NULL
  allg <- NULL
  for (i in 1:length(mcmcCoda)){
  allr <- c(allr,mcmcCoda2[[i]][,26])
  allg <- c(allg,mcmcCoda2[[i]][,27])  
  }

  posteriorweights[freq,ch,m+(expt-1)*4,1,] <- allr
  posteriorweights[freq,ch,m+(expt-1)*4,2,] <- allg

}

currentch <- ch
currentexpt <- expt
currentfreq <- freq
save(file='temp/modelweights.RData',list=c('posteriorparams','posteriorweights','currentch','currentexpt','currentfreq'))

}
currentch <- 1
}
currentexpt <- 1
}

}

load('temp/modelweights.RData')

```

The target stimulus evoked strong steady-state responses at both the first harmonic frequency (5 Hz) and the second harmonic frequency (10 Hz). Figure \@ref(fig:fftfig)a shows the averaged Fourier spectrum from the baseline (no mask) condition with 96% target contrast. Responses at both frequencies were strongest at the occipital pole, over early visual cortex (see inset scalp plots). At most electrodes, responses increased monotonically as a function of contrast (see examples in Figure \@ref(fig:fftfig)b,c). In general, responses at the first harmonic (5Hz) were more likely to accelerate, and those at the second harmonic more likely to saturate or super-saturate. The scalp plot insets to Figures \@ref(fig:fftfig)b,c summarise this using a saturation index proposed by @Ledgeway2005. It was calculated by taking the difference between the responses at the highest two contrasts (96% and 48%), and dividing by the maximum response. Values of SI > 1 correspond to acceleration (plotted violet), SI = 1 to saturation (white), and SI < 1 to super-saturation (green). Notice that overall the first harmonic responses accelerate (median SI = 0.10), but that many of the second harmonic responses saturate or super-saturate (median SI = 0.01).

```{r include=FALSE}

# build figure 3
if (runcode==1){
# code starting here generates a figure containing an example spectrum, headplots, and CRFs
  colmatrix1 <- kovesi.diverging_gwv_55_95_c39(101)
  colmatrix2 <- kovesi.linear_kry_5_98_c75(101)
  colmax <- c(6,3)
  greycols <- c('black','grey45','grey85')
  
  # calculate the saturation index (based on Ledgeway 2005)
  satindex <- matrix(0,nrow=4,ncol=64)
  for (t in 1:2){
    for (ch in 1:64){
      temp <- meanSNRlow[1,2:6,ch,tindex[t]]
      satindex[t,ch] <- (temp[5]-temp[4])/(max(temp))
      temp <- meanSNRhi[1,2:6,ch,tindex[t]]
      satindex[t+2,ch] <- (temp[5]-temp[4])/(max(temp))
    }}
  
  rmax <- 0.55   #specify a maximum boundary for the grid
  gridRes <- 100 #specify the interpolation grid resolution
  xpos <- 1:64
  ypos <- 1:64
  montageE <- toupper(as.character(hdata$Electrode))
  for (ch in 1:64){
    i <- match(toupper(electrodes[ch+2]),montageE)
    xpos[ch] <- hdata$X_position[i]
    ypos[ch] <- hdata$Y_position[i]
  }
  focuselectrodes <- match(c('OZ','P1','T7'),toupper(as.character(electrodes[3:66])))
  
  postscript(paste("temp/Spectrum.ps",sep=''), horizontal = FALSE, onefile = FALSE, paper = "special", height = 5.5, width = 8.5)
  
  plotlims <- c(1,14,0,6) 
  ticklocsx <- seq(1,14,1)    # locations of tick marks on x axis
  ticklocsy <- seq(0,6,1)    # locations of tick marks on y axis
  ticklabelsx <- ticklocsx        # set labels for x ticks
  ticklabelsy <- ticklocsy    # set labels for y ticks
  
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])   
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx)     # add the tick labels
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, las=1)
  title(xlab="Frequency (Hz)", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5) 
  title(ylab="SNR", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)
  
  polygon(c(specfreqs[11:141],specfreqs[141:11]), c(meanSNRlow[1,6,focuselectrodes[1],11:141]+seSNRlow[1,6,focuselectrodes[1],11:141],meanSNRlow[1,6,focuselectrodes[1],141:11]-seSNRlow[1,6,focuselectrodes[1],141:11]), col=rgb(0.5,0.5,0.5),border=NA)
  lines(specfreqs[11:141],meanSNRlow[1,6,focuselectrodes[1],11:141],lwd=2)
  
  dev.off() 
  
  
  for (t in 1:2){
    postscript(paste("temp/CRFs",as.character(electrodes[focuselectrodes[1]+2]),"F",t,".ps",sep=''), horizontal = FALSE, onefile = FALSE, paper = "special", height = 5.5, width = 5.5)
    
    plotlims <- c(0,40,0,6) 
    ticklocsx <- c(0,contrastsdB)    # locations of tick marks on x axis
    ticklocsy <- seq(0,6,1)    # locations of tick marks on y axis
    ticklabelsx <- c(0,6,12,24,48,96)        # set labels for x ticks
    ticklabelsy <- ticklocsy    # set labels for y ticks
    
    par(pty="s")  # make axis square
    plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
    axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
    axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
    mtext(text = ticklabelsx, side = 1, at=ticklocsx)     # add the tick labels
    mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, las=1) 
    title(xlab="Target contrast (%)", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5) 
    title(ylab="SNR", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)
    
    cond <- 1
    
    lines(c(0,40),c(1,1),lty=2)
    
    for (f in 1:length(focuselectrodes)){
      arrows(c(0,contrastsdB),meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]],x1=c(0,contrastsdB), y1=meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]]-seSNRlow[cond,1:6,focuselectrodes[f],tindex[t]], length=0.015, angle=90, lwd=2, col=greycols[f])  # add lower error bar
      arrows(c(0,contrastsdB),meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]],x1=c(0,contrastsdB), y1=meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]]+seSNRlow[cond,1:6,focuselectrodes[f],tindex[t]], length=0.015, angle=90, lwd=2, col=greycols[f])  # add upper error bar
      
      lines(c(0,contrastsdB),abs(meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]]),lwd=2,col=greycols[f])
      points(c(0,contrastsdB),abs(meanSNRlow[cond,1:6,focuselectrodes[f],tindex[t]]),pch=20+f,bg=greycols[f])
    }
    
    if (t==1){legend(32,1.4,c('Oz','P1','T7'),bg='white',text.font=3,pch=21:23,pt.bg=greycols,box.lwd=2)}
    
    dev.off()
  }
  
  for (t in 1:2){
    
    tiff(paste("temp/head",t,".tiff",sep=''), height = 600, width = 600, units="px", bg="white")
    
    testDat <- data.frame(x = xpos, y = -ypos, z = meanSNRlow[1,6,,tindex[t]])
    testDat[which(is.na(testDat[,3])==1),3] <- 1.02
    testDat[which(testDat[,3]<1),3] <- 1.02
    
    #Create the interpolation grid
    xo <- seq(min(-rmax, testDat$x), max(rmax, testDat$x), length = gridRes)
    yo <- seq(max(rmax, testDat$y), min(-rmax, testDat$y), length = gridRes)
    interpV4 <- v4Interp(testDat, xo, yo, rmax, gridRes)
    zo2 <- as.matrix(interpV4[,2:ncol(interpV4)])
    xo2 <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
    yo2 <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
    outsidecircle <- sqrt(xo2^2 + yo2^2) > 0.51
    zo2[outsidecircle] <- 0
    
    plotlims <- c(-rmax,rmax,-rmax,rmax)  
    par(pty="s")  # make axis square
    plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4]) 
    image(xo,xo,zo2,zlim=c(1,colmax[t]),col=colmatrix2,add=TRUE,useRaster=TRUE)
    maskx <- c(hdata$OutlineX[1:51]*2.2,hdata$OutlineX[51:1])
    masky <- c(hdata$OutlineY[1:51]*2.2,hdata$OutlineY[51:1])
    polygon(maskx,masky,border=NA,col="white")
    maskx <- c(hdata$OutlineX[51:101]*2.2,hdata$OutlineX[101:51])
    masky <- c(hdata$OutlineY[51:101]*2.2,hdata$OutlineY[101:51])
    polygon(maskx,masky,border=NA,col="white")
    
    for (f in 1:1){points(xpos[focuselectrodes[f]],ypos[focuselectrodes[f]],pch=20+f,bg=greycols[f],cex=6)}
    
    lines(hdata$OutlineX,hdata$OutlineY,col="black",lwd=2)
    lines(hdata$NoseX,hdata$NoseY,col="black",lwd=2)
    lines(hdata$LearX,hdata$LearY,col="black",lwd=2)
    lines(hdata$RearX,hdata$RearY,col="black",lwd=2)
    
    dev.off()
  }
  
  for (t in 1:2){
    
    tiff(paste("temp/head",t+2,".tiff",sep=''), height = 600, width = 600, units="px", bg="white")
    
    toplot <- (satindex[t,] + satindex[t+2,])/2
    testDat <- data.frame(x = xpos, y = -ypos, z = toplot)
    
    #Create the interpolation grid
    xo <- seq(min(-rmax, testDat$x), max(rmax, testDat$x), length = gridRes)
    yo <- seq(max(rmax, testDat$y), min(-rmax, testDat$y), length = gridRes)
    interpV4 <- v4Interp(testDat, xo, yo, rmax, gridRes)
    zo2 <- as.matrix(interpV4[,2:ncol(interpV4)])
    xo2 <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
    yo2 <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
    outsidecircle <- sqrt(xo2^2 + yo2^2) > 0.51
    zo2[outsidecircle] <- 0
    
    plotlims <- c(-rmax,rmax,-rmax,rmax)  
    par(pty="s")  # make axis square
    plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4]) 
    image(xo,xo,zo2,zlim=c(-0.3,0.3),col=colmatrix1,add=TRUE,useRaster=TRUE)
    maskx <- c(hdata$OutlineX[1:51]*2.2,hdata$OutlineX[51:1])
    masky <- c(hdata$OutlineY[1:51]*2.2,hdata$OutlineY[51:1])
    polygon(maskx,masky,border=NA,col="white")
    maskx <- c(hdata$OutlineX[51:101]*2.2,hdata$OutlineX[101:51])
    masky <- c(hdata$OutlineY[51:101]*2.2,hdata$OutlineY[101:51])
    polygon(maskx,masky,border=NA,col="white")
    
    for (f in 1:3){points(xpos[focuselectrodes[f]],ypos[focuselectrodes[f]],pch=20+f,bg=greycols[f],cex=6)}
    
    lines(hdata$OutlineX,hdata$OutlineY,col="black",lwd=2)
    lines(hdata$NoseX,hdata$NoseY,col="black",lwd=2)
    lines(hdata$LearX,hdata$LearY,col="black",lwd=2)
    lines(hdata$RearX,hdata$RearY,col="black",lwd=2)
    
    dev.off()
  }
  
  
  tiff(paste("temp/colourbar1.tiff",sep=''), height = 600, width = 200, units="px", bg="white")
  colour.bar(colmatrix2, -0.5, 0.5, nticks=0)
  dev.off()
  tiff(paste("temp/colourbar2.tiff",sep=''), height = 600, width = 200, units="px", bg="white")
  colour.bar(colmatrix1, -0.5, 0.5, nticks=0)
  dev.off()
  
  PostScriptTrace(paste('temp/Spectrum.ps',sep=''))
  e1 <- readPicture('Spectrum.ps.xml')
  for (n in 1:length(e1@paths)){
    temp <- class(e1@paths[n]$path)[1]
    if (pmatch(temp,"PictureFill",nomatch=0)){
      if (sum(col2rgb(e1@paths[n]$path@rgb))<765){e1@paths[n]$path@rgb <- addalpha(e1@paths[n]$path@rgb,alpha=0.2)}}}
  
  PostScriptTrace(paste('temp/CRFsOzF1.ps',sep=''))
  e2 <- readPicture('CRFsOzF1.ps.xml')
  PostScriptTrace(paste('temp/CRFsOzF2.ps',sep=''))
  e3 <- readPicture('CRFsOzF2.ps.xml')
  
  e6 <- readTIFF(paste('temp/head1.tiff',sep=''))
  e7 <- readTIFF(paste('temp/head2.tiff',sep=''))
  e8 <- readTIFF(paste('temp/colourbar1.tiff',sep=''))
  e9 <- readTIFF(paste('temp/head3.tiff',sep=''))
  e10 <- readTIFF(paste('temp/head4.tiff',sep=''))
  e11 <- readTIFF(paste('temp/colourbar2.tiff',sep=''))
  
  pdf('figures/fftfig.pdf', bg="transparent", height = 6, width = 6)
  par(mar=c(0.1,0.1,0.1,0.1))
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(0,1), ylim=c(0,1)) 
  
  aspratio <- 6/6  # this is the aspect ratio of the output pdf
  imwidth <- 0.24
  xstart <- 0.14
  ystart <- 0.82
  rasterImage(e6,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  xstart <- 0.64
  rasterImage(e7,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  imwidth <- 0.2
  xstart <- 0.4
  ystart <- 0.85
  rasterImage(e8,xstart,ystart,xstart+imwidth*aspratio/3,ystart+imwidth)
  xstart <- 0.88
  rasterImage(e8,xstart,ystart,xstart+imwidth*aspratio/3,ystart+imwidth)
  
  imwidth <- 0.24
  xstart <- 0.05
  ystart <- 0.22
  rasterImage(e9,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  xstart <- 0.6
  rasterImage(e10,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  imwidth <- 0.2
  xstart <- 0.83
  ystart <- 0.25
  rasterImage(e11,xstart,ystart,xstart+imwidth*aspratio/3,ystart+imwidth)
  
  
  grid.picture(e1,x=0.5,y=0.75,width=1,height=1)
  grid.picture(e2,x=0.25,y=0.24,width=0.45,height=1)
  grid.picture(e3,x=0.75,y=0.24,width=0.45,height=1)
  
  text(-0.05,1.01,'(a)',pos=4,cex=2)
  text(-0.05,0.47,'(b)',pos=4,cex=2)
  text(0.5,0.47,'(c)',pos=4,cex=2)
  
  text(0.15,0.47,'1F: 5Hz',pos=4,cex=2)
  text(0.67,0.47,'2F: 10Hz',pos=4,cex=2)
  
  text(0.44,0.88,'1',pos=4,cex=1.2)
  text(0.44,1.02,'6',pos=4,cex=1.2)
  text(0.46,0.985,'SNR',pos=4,cex=1,srt=270)
  text(0.92,0.88,'1',pos=4,cex=1.2)
  text(0.92,1.02,'3',pos=4,cex=1.2)
  text(0.94,0.985,'SNR',pos=4,cex=1,srt=270)
  text(0.87,0.28,'-0.3',pos=4,cex=1.2)
  text(0.875,0.42,'0.3',pos=4,cex=1.2)
  text(0.89,0.37,'SI',pos=4,cex=1.2,srt=270)
  
  dev.off()
  
  file.remove(c('temp/Spectrum.ps','temp/CRFsOzF1.ps','temp/CRFsOzF2.ps','temp/head1.tiff','temp/head2.tiff','temp/head3.tiff','temp/head4.tiff','temp/colourbar1.tiff','temp/colourbar2.tiff'))
  file.remove(c('Spectrum.ps.xml','CRFsOzF1.ps.xml','CRFsOzF2.ps.xml'))
  
}

```
  
```{r fftfig, fig.cap="Averaged Fourier spectrum and example contrast response functions. Panel (a) shows the spectrum for a high contrast target, with inset scalp plots showing SNRs at the first and second harmonic frequencies. The spectrum is taken from electrode Oz, indicated by the black points in the scalp plots. The shaded region and error bars indicate ±1 standard error. Panels (b) and (c) show example contrast response functions at the first and second harmonics at electrodes Oz, P1 and T7, averaged across participants (N=12). The inset scalp plots show how the saturation index varies across the head.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/fftfig.pdf')

```

To quantify how suppression varied across the scalp, and across different mask types and response frequencies, we fitted a hierarchical Bayesian model to the data. The first stage of this process involved estimating values for the free parameters in equation \@ref(eq:GC1). Figure \@ref(fig:modelfig1)a shows an example fit at electrode _Oz_ for the low contrast mask experiment. The thick black line gives the fit using the posterior mean parameter estimates (_p_ = `r round(mean(posteriorparams[1,31,2,]),digits=2)`, _Z_ = `r round(mean(posteriorparams[1,31,1,]),digits=2)`, $R_{max}$ = `r round(mean(posteriorparams[1,31,3,]),digits=2)`), and thin lines show predictions for 100 randomly sampled posterior parameter combinations. At the second stage of fitting, we estimated values of the suppressive parameters _g_ and _r_ for each mask type. Example fits are shown in Figure \@ref(fig:modelfig1)b-e, with accompanying posterior distributions of parameter estimates in panels g-j. We assess whether a parameter makes a credible contribution to the response by determining whether the 95% highest density interval of the posterior (shown by the black bars at the margins of Figure \@ref(fig:modelfig1)g-j) encompasses 1. For all four examples shown in Figure \@ref(fig:modelfig1)g-j, the contrast gain parameter (_g_, y-axis) was credibly greater than 1, whereas the response gain parameter (_r_, x-axis) was not credibly different from 1. This is evidence that all four mask types modulate responses via contrast gain control at electrode _Oz_, for the first harmonic response.

```{r include=FALSE}

# create Figure 4 & 6
if (runcode==1){
  
nchains <- 12000  
meanparams <- apply(posteriorparams,1:3,mean)  
meanweights <- apply(posteriorweights,1:4,mean)

xvals <- seq(0,15,0.01)
gamprior <- dgamma(xvals,shape=1.5,rate=0.5)
gamprior <- gamprior/max(gamprior)

expt <- 1
for (freq in 1:2){
index2 <- which(xvals==(2*freq))

titletext <- c('Baseline','Monocular','Dichoptic','Aligned surround','Orthogonal surround')

pdf(paste('figures/modelfig',freq,'.pdf',sep=''), bg="transparent", height = 5, width = 10)

ramp <- colorRamp(c("white", rgb(56/255,111/255,164/255)))
colmatrix2 <- rgb(ramp(seq(0, 1, length = 100)), max = 255) 

par(mfrow=c(2,5), mar=c(2,3,2,1))
  
finecontsdB <- 0:40
finecontsC <- 10^(finecontsdB/20)
finecontsC[1] <- 0

  plotlims <- c(0,40,0,6/freq) 
  ticklocsy <- seq(0,6/freq,1)    # locations of tick marks on y axis
  ticklocsx <- c(0,contrastsdB)    
  ticklabelsx <- c(0,6,12,24,48,96)        # set labels for x ticks
  ticklabelsy <- ticklocsy    # set labels for y ticks
  
  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx, line=0.2, cex=0.8)     
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, cex=0.8, las=1) 
  title(xlab="Target contrast (%)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5) 
  title(ylab="SNR", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)
  title(main=titletext[1])

for (i in 1:100){
  index <- sample(1:nchains,1)
resp <- 1 + posteriorparams[freq,31,3+(expt-1)*3,index]*(finecontsC^posteriorparams[freq,31,2+(expt-1)*3,index])/(posteriorparams[freq,31,1+(expt-1)*3,index] + finecontsC^2)
lines(finecontsdB,resp,lwd=1,col=addalpha(colourlist[1],0.1))
}

resp <- 1 + meanparams[freq,31,3+(expt-1)*3]*(finecontsC^meanparams[freq,31,2+(expt-1)*3])/(meanparams[freq,31,1+(expt-1)*3] + finecontsC^2)
lines(finecontsdB,resp,lwd=3)
lines(c(0,40),c(1,1),lty=2)

if (expt==1){points(c(0,contrastsdB),meanSNRlow[1,1:6,31,tindex[freq]],pch=21,bg='black')}
if (expt==2){points(c(0,contrastsdB),meanSNRhi[1,1:6,31,tindex[freq]],pch=21,bg='black')}
text(-3,5.5,'(a)',pos=4,cex=2)

for (m in 1:4){

  tempconts <- contrastsdB
  if (expt==1){if (m==1){tempconts <- lowmoncontsdB}}
  if (expt==1){if (m==1){tempconts <- himoncontsdB}}
  
  plotlims <- c(0,40,0,6/freq) 
  ticklocsx <- c(0,contrastsdB)    # locations of tick marks on x axis
  ticklocsy <- seq(0,6/freq,1)    # locations of tick marks on y axis
  ticklabelsx <- c(0,6,12,24,48,96)        # set labels for x ticks
  ticklabelsy <- ticklocsy    # set labels for y ticks
  
  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx, line=0.2, cex=0.8)     
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, cex=0.8, las=1) 
  title(xlab="Target contrast (%)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5) 
  title(ylab="SNR", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)
title(main=titletext[m+1])

for (i in 1:100){
  index <- sample(1:nchains,1)
resp <- 1 + (meanparams[freq,31,3+(expt-1)*3]/posteriorweights[freq,31,m+(expt-1)*4,1,index])*(finecontsC^meanparams[freq,31,2+(expt-1)*3])/(posteriorweights[freq,31,m+(expt-1)*4,2,index]*meanparams[freq,31,1+(expt-1)*3] + finecontsC^2)
lines(finecontsdB,resp,lwd=1,col=addalpha(colourlist[m+1],0.1))
}
  
resp <- 1 + meanparams[freq,31,3+(expt-1)*3]*(finecontsC^meanparams[freq,31,2+(expt-1)*3])/(meanparams[freq,31,1+(expt-1)*3] + finecontsC^2)
lines(finecontsdB,resp,col='grey',lwd=3)
resp <- 1 + (meanparams[freq,31,3+(expt-1)*3]/meanweights[freq,31,m+(expt-1)*4,1])*(finecontsC^meanparams[freq,31,2+(expt-1)*3])/(meanweights[freq,31,m+(expt-1)*4,2]*meanparams[freq,31,1+(expt-1)*3] + finecontsC^2)
lines(finecontsdB,resp,lwd=3,col=colourlist[m+1])

lines(c(0,40),c(1,1),lty=2)
if (expt==1){arrows(20*log10(12), 0.75/freq, x1=20*log10(12), y1 = 0, length=0.05, lwd=2)}
if (expt==2){arrows(20*log10(24), 0.75/freq, x1=20*log10(24), y1 = 0, length=0.05, lwd=2)}

if (expt==1){points(tempconts,meanSNRlow[m+1,1:5,31,tindex[freq]],pch=21+m,bg=colourlist[m+1])}
if (expt==2){points(tempconts,meanSNRhi[m+1,1:5,31,tindex[freq]],pch=21+m,bg=colourlist[m+1])}
text(-3,5.5,paste('(',letters[m+1],')',sep=''),pos=4,cex=2)

}

  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=c(-0.7,0.7), ylim=c(-0.7,0.7))

  points(xpos,ypos,pch=16,col='grey',cex=1)

  blackelectrodes <- match('OZ',toupper(as.character(electrodes[3:66])))
  points(xpos[blackelectrodes],ypos[blackelectrodes],pch=16,col='black',cex=2)

  lines(hdata$OutlineX,hdata$OutlineY,col="black",lwd=1.5)
  lines(hdata$NoseX,hdata$NoseY,col="black",lwd=1.5)
  lines(hdata$LearX,hdata$LearY,col="black",lwd=1.5)
  lines(hdata$RearX,hdata$RearY,col="black",lwd=1.5)
text(-0.75,0.6,paste('(',letters[6],')',sep=''),pos=4,cex=2)

  
  for (m in 1:4){
    
  plotlims <- c(0,2*freq,0,15) 
  ticklocsx <- seq(0,2*freq,0.5*freq)
  ticklocsy <- seq(0,15,5)    # locations of tick marks on y axis
  ticklabelsx <- ticklocsx        # set labels for x ticks
  ticklabelsy <- ticklocsy    # set labels for y ticks
  
  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx, line=0.2, cex=0.8)     
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, cex=0.8, las=1) 
  title(xlab="Response gain (r)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5) 
  title(ylab="Contrast gain (g)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)

k <- kde2d(posteriorweights[freq,31,m+(expt-1)*4,1,],posteriorweights[freq,31,m+(expt-1)*4,2,],n=200)
image(k$x,k$y,k$z,col=colmatrix2,add=TRUE)
# plot(allZ,allp,type='p',pch=20,col=rgb(0,0,0,alpha=0.1))
# contour(k$x,k$y,k$z,col='blue',add=TRUE)
points(mean(posteriorweights[freq,31,m+(expt-1)*4,1,]),mean(posteriorweights[freq,31,m+(expt-1)*4,2,]),pch=16,col='red')

lines(xvals[1:index2],15-(3*gamprior[1:index2]),col='grey')
lines((2*freq)-(freq*0.4*gamprior),xvals,col='grey')

a <- density(posteriorweights[freq,31,m+(expt-1)*4,1,],from=0,to=2*freq)
a$y <- 3*a$y/max(a$y)
lines(a$x,15-a$y,col=colourlist[m+1],lwd=2)
ci <- hdi(posteriorweights[freq,31,m+(expt-1)*4,1,],ci=hdirange)
arrows(ci$CI_low,14.8, x1=ci$CI_high, y1=14.8,length=0.015, angle=90, lwd=2)
arrows(ci$CI_high,14.8, x1=ci$CI_low, y1=14.8,length=0.015, angle=90, lwd=2)

a <- density(posteriorweights[freq,31,m+(expt-1)*4,2,],from=0,to=15)
a$y <- freq*0.4*a$y/max(a$y)
lines((2*freq)-a$y,a$x,col=colourlist[m+1],lwd=2)
ci <- hdi(posteriorweights[freq,31,m+(expt-1)*4,2,],ci=hdirange)
arrows(freq*1.95,ci$CI_low,x1=freq*1.95,y1=ci$CI_high,length=0.015, angle=90, lwd=2)
arrows(freq*1.95,ci$CI_high,x1=freq*1.95,y1=ci$CI_low,length=0.015, angle=90, lwd=2)


lines(c(1,1),c(0,15),lty=2)  
lines(c(0,2*freq),c(1,1),lty=2)  
text(-0.15,13.5,paste('(',letters[m+6],')',sep=''),pos=4,cex=2)

  }

dev.off()
}
}

```
  
```{r modelfig1, fig.cap="Contrast response functions from electrode Oz, with example model fits and posterior parameter estimates. Panel (a) shows the data from the baseline (no mask) condition (points), plotted alongside model curves for the posterior mean of parameter estimates (thick curve), and random posterior samples (thin curves). Panels (b-e) show data for four types of mask in the same format (grey curves duplicate the mean fit from panel (a)), with the arrows indicating the mask contrast. Panel (f) shows the electrode location. Panels (g-j) show posterior density estimates for the response gain (x-axis) and contrast gain (y-axis) weight parameters. Red points show the means, dashed lines give the value expected in the case of no effect (a weight of 1), and grey and coloured distributions in the margins show the prior and posterior for each parameter. For all mask types, the contrast gain weight estimate was substantially greater than 1.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/modelfig1.pdf')

```

## Suppression across electrode and scalp location

We repeated the above analysis independently at each electrode, for each response frequency (5 Hz and 10 Hz), and for both experiments (12% and 24% mask contrast). Figure \@ref(fig:modelheads1) summarises the results for the 12% mask contrast experiment, and for each mask type. For the first harmonic (5 Hz) response (top two rows), there were strong contrast gain control effects (panels a-d), but little credible effect of response gain (panels e-h). For the second harmonic response (10 Hz), although some contrast gain effects were credible at the occipital pole (electrode _Oz_ for all mask types, panels i-l), suppression was also well described by response gain (panels m-p). Example contrast response functions and posterior distributions at the second harmonic are shown in Figure \@ref(fig:modelfig2). This overall pattern was replicated in our second data set with higher (24%) contrast masks (Figure \@ref(fig:modelheads2)).

```{r include=FALSE}

# create Figures 5 & 7
if (runcode==1){
  ptscl <- 2   # constant to scale the point size of the electrodes
  
  for (expt in 1:2){
  
  issignificant <- array(0,dim=c(2,2,4,64))
  for (freq in 1:2){
    for (m in 1:4){
  for (ch in 1:64){
    for (param in 1:2){
  ci <- hdi(posteriorweights[freq,ch,m+(expt-1)*4,param,],ci=hdirange)
  if (ci$CI_low>1){issignificant[param,freq,m,ch] <- 1}
    }}}}
  
  pdf(paste('figures/modelheads',expt,'.pdf',sep=''), bg="transparent", height = 10, width = 10)
  
  plotlims <- c(0,4.6,0,4.6)
  par(mar=c(0.1,0.1,0.1,0.1))
  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  
  freq <- 1
for (m in 1:4){
xoffset <- 1.1*(m-1)+0.55
yoffset <- 1.1*3.5
datatoplot <- meanweights[freq,,m+(expt-1)*4,2]
datatoplot[which(datatoplot<1)] <- 0
sigthresh <- issignificant[2,freq,m,]

  points(xpos[which(sigthresh<1)]+xoffset,ypos[which(sigthresh<1)]+yoffset,pch=21,col=colourlist[m+1],bg='white',cex=datatoplot[which(sigthresh<1)]/ptscl)
  points(xpos[which(sigthresh==1)]+xoffset,ypos[which(sigthresh==1)]+yoffset,pch=21,col=colourlist[m+1],bg=addalpha(colourlist[m+1],0.5),cex=datatoplot[which(sigthresh==1)]/ptscl)
  
  lines(hdata$OutlineX+xoffset,hdata$OutlineY+yoffset,col="black",lwd=2)
  lines(hdata$NoseX+xoffset,hdata$NoseY+yoffset,col="black",lwd=2)
  lines(hdata$LearX+xoffset,hdata$LearY+yoffset,col="black",lwd=2)
  lines(hdata$RearX+xoffset,hdata$RearY+yoffset,col="black",lwd=2)
}

for (m in 1:4){
xoffset <- 1.1*(m-1)+0.55
yoffset <- 1.1*2.5
datatoplot <- meanweights[freq,,m+(expt-1)*4,1]
datatoplot[which(datatoplot<1)] <- 0
sigthresh <- issignificant[1,freq,m,]

  points(xpos[which(sigthresh<1)]+xoffset,ypos[which(sigthresh<1)]+yoffset,pch=21,col=colourlist[m+1],bg='white',cex=datatoplot[which(sigthresh<1)]/ptscl)
  points(xpos[which(sigthresh==1)]+xoffset,ypos[which(sigthresh==1)]+yoffset,pch=21,col=colourlist[m+1],bg=addalpha(colourlist[m+1],0.5),cex=datatoplot[which(sigthresh==1)]/ptscl)

  lines(hdata$OutlineX+xoffset,hdata$OutlineY+yoffset,col="black",lwd=2)
  lines(hdata$NoseX+xoffset,hdata$NoseY+yoffset,col="black",lwd=2)
  lines(hdata$LearX+xoffset,hdata$LearY+yoffset,col="black",lwd=2)
  lines(hdata$RearX+xoffset,hdata$RearY+yoffset,col="black",lwd=2)
}
  
  freq <- 2
for (m in 1:4){
xoffset <- 1.1*(m-1)+0.55
yoffset <- 1.1*1.5
datatoplot <- meanweights[freq,,m+(expt-1)*4,2]
datatoplot[which(datatoplot<1)] <- 0
sigthresh <- issignificant[2,freq,m,]

  points(xpos[which(sigthresh<1)]+xoffset,ypos[which(sigthresh<1)]+yoffset,pch=21,col=colourlist[m+1],bg='white',cex=datatoplot[which(sigthresh<1)]/ptscl)
  points(xpos[which(sigthresh==1)]+xoffset,ypos[which(sigthresh==1)]+yoffset,pch=21,col=colourlist[m+1],bg=addalpha(colourlist[m+1],0.5),cex=datatoplot[which(sigthresh==1)]/ptscl)

    lines(hdata$OutlineX+xoffset,hdata$OutlineY+yoffset,col="black",lwd=2)
  lines(hdata$NoseX+xoffset,hdata$NoseY+yoffset,col="black",lwd=2)
  lines(hdata$LearX+xoffset,hdata$LearY+yoffset,col="black",lwd=2)
  lines(hdata$RearX+xoffset,hdata$RearY+yoffset,col="black",lwd=2)
}

for (m in 1:4){
xoffset <- 1.1*(m-1)+0.55
yoffset <- 1.1*0.5
datatoplot <- meanweights[freq,,m+(expt-1)*4,1]
datatoplot[which(datatoplot<1)] <- 0
sigthresh <- issignificant[1,freq,m,]

  points(xpos[which(sigthresh<1)]+xoffset,ypos[which(sigthresh<1)]+yoffset,pch=21,col=colourlist[m+1],bg='white',cex=datatoplot[which(sigthresh<1)]/ptscl)
  points(xpos[which(sigthresh==1)]+xoffset,ypos[which(sigthresh==1)]+yoffset,pch=21,col=colourlist[m+1],bg=addalpha(colourlist[m+1],0.5),cex=datatoplot[which(sigthresh==1)]/ptscl)

    lines(hdata$OutlineX+xoffset,hdata$OutlineY+yoffset,col="black",lwd=2)
  lines(hdata$NoseX+xoffset,hdata$NoseY+yoffset,col="black",lwd=2)
  lines(hdata$LearX+xoffset,hdata$LearY+yoffset,col="black",lwd=2)
  lines(hdata$RearX+xoffset,hdata$RearY+yoffset,col="black",lwd=2)
}
  
  lettercount <- 0
  for (row in 1:4){
    for (col in 1:4){
    lettercount <- lettercount + 1
    text((col-1)*1.1+0.1,4.3-(row-1)*1.1,paste('(',letters[lettercount],')',sep=''),cex=1.25)
  }}
  
  text(0.55,4.5,'Monocular',cex=1.25)
  text(1.65,4.5,'Dichoptic',cex=1.25)
  text(2.75,4.5,'Aligned surround',cex=1.25)
  text(3.85,4.5,'Orthogonal surround',cex=1.25)
  
  text(4.6,3.85,'Contrast gain (g)',srt=270)
  text(4.5,3.85,'First harmonic (5Hz)',srt=270)
  text(4.6,2.75,'Response gain (r)',srt=270)
  text(4.5,2.75,'First harmonic (5Hz)',srt=270)
  text(4.6,1.65,'Contrast gain (g)',srt=270)
  text(4.5,1.65,'Second harmonic (10Hz)',srt=270)
  text(4.6,0.55,'Response gain (r)',srt=270)
  text(4.5,0.55,'Second harmonic (10Hz)',srt=270)
  
  points(3.55,0,pch=21,col='grey',bg='grey',cex=1/ptscl)
  points(3.75,0,pch=21,col='grey',bg='grey',cex=2/ptscl)
  points(3.95,0,pch=21,col='grey',bg='grey',cex=4/ptscl)
  points(4.15,0.02,pch=21,col='grey',bg='grey',cex=8/ptscl)
  text(3.55,-0.12,'1')
  text(3.75,-0.12,'2')
  text(3.95,-0.12,'4')
  text(4.15,-0.12,'8')
  
  dev.off()
  }
}

```

```{r modelheads1, fig.cap="Scalp plots summarising the suppressive weights for contrast and response gain from the Bayesian hierarchical model, fitted to data from the low mask contrast experiment. Symbols are filled white when the 95 percent highest density interval of the posterior parameter distribution includes 1 (implying no credible contribution from that type of suppression). Larger symbols correspond to stronger suppression (see the scale in lower right corner), but parameters implying facilitation (values < 1) are not plotted.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/modelheads1.pdf')

```

```{r modelfig2, fig.cap="Contrast response functions at the second harmonic frequency. Plotting conventions mirror those in Figure 3. Note that the lower SNR at 10 Hz results in noisier data and less precise posterior estimates than at 5 Hz.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/modelfig2.pdf')

```

Closer inspection of these results reveals some interesting subtleties and differences across mask conditions. Note in particular that the weights for surround suppression at the first harmonic are generally weaker at the occipital pole (electrodes _Oz_ and _POz_) than for monocular and dichoptic suppression. But suppressive weights increase at bilateral electrodes over more parietal regions of cortex. For surround suppression, this might reflect the increased suppression in extra-striate cortical regions that have larger receptive fields. More generally, it suggests that suppression builds up across successive stages of processing. It also appears that, whereas suppression at the first harmonic is primarily due to contrast gain control, suppression at the second harmonic involves changes in both contrast and response gain (see lower two rows of Figures \@ref(fig:modelheads1) & \@ref(fig:modelheads2)). This may well reflect the involvement of different classes of neurons - for example, second harmonic responses imply more severe nonlinearities, which might include suppression. This is also consistent with the greater saturation of the second harmonic response (inset to Figure \@ref(fig:modelfig1)c).

```{r modelheads2, fig.cap="Scalp plots summarising the suppressive weights for contrast and response gain from the Bayesian hierarchical model, fitted to data from the high mask contrast experiment. Plotting conventions are as for Figure 5.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/modelheads2.pdf')

```

## Limited saturation of mask signals

Finally, we asked about the properties of the mask signal. Of particular interest is whether the mask signal itself saturates before suppressing the target. If it does, this implies the presence of a nonlinearity before suppression impacts, as has been shown psychophysically for surround masks [@Meese2009]. Figure \@ref(fig:masksignals)a shows model predictions for a linear suppressive signal (black curve), and a saturating suppressive signal (red curve). We therefore measured responses at a fixed (24%) target contrast, for mask contrasts that ranged from 0% to 96%. For this analysis, we pooled data across the two experiments, giving us N = 21 participants (data for the three participants who completed both experiments were averaged to give a single data set for each of those participants). The results for all four mask types are shown in Figure \@ref(fig:masksignals)b-e. At both the first and second harmonic frequencies, the target response decreased as a function of mask contrast. For the highest contrast monocular and dichoptic masks, this resulted in an almost complete suppression of the target response (SNR ~ 1). For the surround masks at the first harmonic there was still a substantial signal even with the highest (96%) contrast masks.

```{r include=FALSE}

# create Figure 8
if (runcode==1){
  xvals <- matrix(0,nrow=4,ncol=5)
  xvals[1,] <- 20*log10(c(6,12,24,48,68))
  xvals[2,] <- 20*log10(c(6,12,24,48,96))
  xvals[3,] <- 20*log10(c(6,12,24,48,96))
  xvals[4,] <- 20*log10(c(6,12,24,48,96))
  
  baselineallS <- array(0,dim=c(21,2,64))
  floorallS <- array(0,dim=c(21,2,64))
  dataallS <- array(0,dim=c(21,4,5,2,64))
  for (f in 1:2){
  for (ch in 1:64){
  
  baselineallS[1,f,ch] <- allSNRlow[3,1,4,ch,tindex[f]] + allSNRhi[3,1,4,ch,tindex[f]]
  baselineallS[2,f,ch] <- allSNRlow[6,1,4,ch,tindex[f]] + allSNRhi[5,1,4,ch,tindex[f]]
  baselineallS[3,f,ch] <- allSNRlow[8,1,4,ch,tindex[f]] + allSNRhi[7,1,4,ch,tindex[f]]
  included <- c(1,2,4,5,7,9,10,11,12)
  for (n in 1:length(included)){
    baselineallS[n+3,f,ch] <- allSNRlow[included[n],1,4,ch,tindex[f]]
  }
  included <- c(1,2,4,6,8,9,10,11,12)
  for (n in 1:length(included)){
    baselineallS[n+12,f,ch] <- allSNRhi[included[n],1,4,ch,tindex[f]]
  }  
  
  floorallS[1,f,ch] <- allSNRlow[3,1,1,ch,tindex[f]] + allSNRhi[3,1,1,ch,tindex[f]]
  floorallS[2,f,ch] <- allSNRlow[6,1,1,ch,tindex[f]] + allSNRhi[5,1,1,ch,tindex[f]]
  floorallS[3,f,ch] <- allSNRlow[8,1,1,ch,tindex[f]] + allSNRhi[7,1,1,ch,tindex[f]]
  included <- c(1,2,4,5,7,9,10,11,12)
  for (n in 1:length(included)){
    floorallS[n+3,f,ch] <- allSNRlow[included[n],1,1,ch,tindex[f]]
  }
  included <- c(1,2,4,6,8,9,10,11,12)
  for (n in 1:length(included)){
    floorallS[n+12,f,ch] <- allSNRhi[included[n],1,1,ch,tindex[f]]
  }  


  for (m in 1:4){  
  dataallS[1,m,,f,ch] <- allSNRlow[3,m+1,c(6,3,7:9),ch,tindex[f]] + allSNRhi[3,m+1,c(6,7,3,8:9),ch,tindex[f]]
  dataallS[2,m,,f,ch] <- allSNRlow[6,m+1,c(6,3,7:9),ch,tindex[f]] + allSNRhi[5,m+1,c(6,7,3,8:9),ch,tindex[f]]
  dataallS[3,m,,f,ch] <- allSNRlow[8,m+1,c(6,3,7:9),ch,tindex[f]] + allSNRhi[7,m+1,c(6,7,3,8:9),ch,tindex[f]]
  included <- c(1,2,4,5,7,9,10,11,12)
  for (n in 1:length(included)){
    dataallS[n+3,m,,f,ch] <- allSNRlow[included[n],m+1,c(6,3,7:9),ch,tindex[f]]
  }
  included <- c(1,2,4,6,8,9,10,11,12)
  for (n in 1:length(included)){
    dataallS[n+12,m,,f,ch] <- allSNRhi[included[n],m+1,c(6,7,3,8:9),ch,tindex[f]]
  }  
  }
}}

  baseline <- apply(baselineallS,c(2,3),mean)
  baselineSE <- apply(baselineallS,c(2,3),sd)/sqrt(21)
  floorval <- apply(floorallS,c(2,3),mean)
  floorSE <- apply(floorallS,c(2,3),sd)/sqrt(21)  
  maskdatamean <- apply(dataallS,c(2,3,4,5),mean)
  maskdataSE <- apply(dataallS,c(2,3,4,5),sd)/sqrt(21)

SImask <- array(0,dim=c(4,2,64))
for (f in 1:2){
  for (ch in 1:64){
for (m in 1:4){
  SImask[m,f,ch] <- (maskdatamean[m,4,f,ch] - maskdatamean[m,5,f,ch])/min(maskdatamean[m,,f,ch])
}}}
SImask[1,,] <- sqrt(2)*SImask[1,,]  # compensate for different contrasts


  tiff(paste("temp/colourbar.tiff",sep=''), height = 600, width = 200, units="px", bg="white")
  colour.bar(colmatrix1, -0.5, 0.5, nticks=0)
  dev.off()
  fcols <- c('black','grey')

  for (f in 1:2){
    for (m in 1:4){
    tiff(paste("temp/SIheadF",f,'M',m,".tiff",sep=''), height = 600, width = 600, units="px", bg="white")
    
    toplot <- SImask[m,f,]
    testDat <- data.frame(x = xpos, y = -ypos, z = toplot)
    
    #Create the interpolation grid
    xo <- seq(min(-rmax, testDat$x), max(rmax, testDat$x), length = gridRes)
    yo <- seq(max(rmax, testDat$y), min(-rmax, testDat$y), length = gridRes)
    interpV4 <- v4Interp(testDat, xo, yo, rmax, gridRes)
    zo2 <- as.matrix(interpV4[,2:ncol(interpV4)])
    xo2 <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
    yo2 <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
    outsidecircle <- sqrt(xo2^2 + yo2^2) > 0.51
    zo2[outsidecircle] <- 0
    
    plotlims <- c(-rmax,rmax,-rmax,rmax)  
    par(pty="s",mar=c(0,0,0,0))  # make axis square
    plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4]) 
    image(xo,xo,zo2,zlim=c(-0.8,0.8),col=colmatrix1,add=TRUE,useRaster=TRUE)
    maskx <- c(hdata$OutlineX[1:51]*2.2,hdata$OutlineX[51:1])
    masky <- c(hdata$OutlineY[1:51]*2.2,hdata$OutlineY[51:1])
    polygon(maskx,masky,border=NA,col="white")
    maskx <- c(hdata$OutlineX[51:101]*2.2,hdata$OutlineX[101:51])
    masky <- c(hdata$OutlineY[51:101]*2.2,hdata$OutlineY[101:51])
    polygon(maskx,masky,border=NA,col="white")
    
    lines(hdata$OutlineX,hdata$OutlineY,col="black",lwd=3)
    lines(hdata$NoseX,hdata$NoseY,col="black",lwd=3)
    lines(hdata$LearX,hdata$LearY,col="black",lwd=3)
    lines(hdata$RearX,hdata$RearY,col="black",lwd=3)
    
    dev.off()
  }}

  plotlims <- c(0,40,0,6) 
  ticklocsy <- seq(0,6,1)    # locations of tick marks on y axis
  ticklocsx <- c(0,contrastsdB)
  ticklabelsx <- c(0,6,12,24,48,96)        # set labels for x ticks
  ticklabelsy <- ticklocsy    # set labels for y ticks
  
  titletext <- c('Model predictions','Monocular','Dichoptic','Aligned surround','Orthogonal surround')

pdf(paste('figures/masksignals.pdf',sep=''), bg="transparent", height = 5, width = 10)

par(mfrow=c(2,5), mar=c(2,3,2,1))

  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx, line=0.2, cex=0.8)     
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, cex=0.8, las=1) 
  title(xlab="Mask contrast (%)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)
  title(ylab="SNR", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)
  title(main=titletext[1])
  lines(c(0,40),c(1,1))
text(3,5.8,paste('(',letters[1],')',sep=''),cex=1.5)

p <- 1.94
Rmax <- 4.8
Z <- 134
C <- 24
linearresp <- 1 + Rmax*(C^p)/(Z + C^2 + 50*finecontsC)
lines(finecontsdB,linearresp,lwd=2)
masksignal <- (finecontsC^p)/(Z + finecontsC^2)
satresp <- 1 + Rmax*(C^p)/(Z + C^2 + 2000*masksignal^2)
lines(finecontsdB,satresp,col='red',lty=2,lwd=2)
legend(12,6,c('Linear','Saturating'),col=c('black','red'),lwd=2,lty=1:2,box.lwd=1.5)

for (m in 1:4){
  par(pty="s")  # make axis square
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklabelsx, side = 1, at=ticklocsx, line=0.2, cex=0.8)     
  mtext(text = ticklabelsy, side = 2, at=ticklocsy, line=0.2, cex=0.8, las=1) 
  title(xlab="Mask contrast (%)", col.lab=rgb(0,0,0), line=1.5, cex.lab=1.5)
  title(ylab="SNR", col.lab=rgb(0,0,0), line=1.2, cex.lab=1.5)
  title(main=titletext[m+1])
  
  for (f in 1:2){
arrows(0,baseline[f,focuselectrodes[1]],x1=0, y1=baseline[f,focuselectrodes[1]]+baselineSE[f,focuselectrodes[1]], length=0.015, angle=90, lwd=2, col=fcols[f])
arrows(0,baseline[f,focuselectrodes[1]],x1=0, y1=baseline[f,focuselectrodes[1]]-baselineSE[f,focuselectrodes[1]], length=0.015, angle=90, lwd=2, col=fcols[f])
points(0,baseline[f,focuselectrodes[1]],pch=21,col=fcols[f],bg=fcols[f])
  
polygon(c(0,40,40,0),floorval[f,focuselectrodes[1]]+c(floorSE[f,focuselectrodes[1]],floorSE[f,focuselectrodes[1]],-floorSE[f,focuselectrodes[1]],-floorSE[f,focuselectrodes[1]]),border=NA,col=rgb(0,0,0,alpha=0.1))
lines(c(0,40),c(floorval[f,focuselectrodes[1]],floorval[f,focuselectrodes[1]]),lty=(f-1)*2+1)

arrows(xvals[m,],maskdatamean[m,,f,focuselectrodes[1]],x1=xvals[m,], y1=maskdatamean[m,,f,focuselectrodes[1]]+maskdataSE[m,,f,focuselectrodes[1]], length=0.015, angle=90, lwd=2, col=colourlist[m+1])
arrows(xvals[m,],maskdatamean[m,,f,focuselectrodes[1]],x1=xvals[m,], y1=maskdatamean[m,,f,focuselectrodes[1]]-maskdataSE[m,,f,focuselectrodes[1]], length=0.015, angle=90, lwd=2, col=colourlist[m+1])
  
lines(xvals[m,],maskdatamean[m,,f,focuselectrodes[1]],col=colourlist[m+1],lwd=2)
if (f==1){points(xvals[m,],maskdatamean[m,,f,focuselectrodes[1]],pch=21+m, col='black',bg=colourlist[m+1])}
if (f==2){points(xvals[m,],maskdatamean[m,,f,focuselectrodes[1]],pch=21+m, bg='black',col=colourlist[m+1])}
  }
  
text(21,6,paste('1F SI:',round(SImask[m,1,focuselectrodes[1]],digits=2)),pos=4)  
text(21,5.5,paste('2F SI:',round(SImask[m,2,focuselectrodes[1]],digits=2)),pos=4)  
  
arrows(20*log10(24), 0.75, x1=20*log10(24), y1 = 0, length=0.05, lwd=2)
text(3,5.8,paste('(',letters[m+1],')',sep=''),cex=1.5)

}

  par(pty='m')
  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(0,1), ylim=c(0,1))
  # plot the colour bar here
  aspratio <- 1/3
  imwidth <- 0.6
  xstart <- 0.25
  ystart <- 0.2
  e1 <- readTIFF('temp/colourbar.tiff')
  rasterImage(e1,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  text(0.41,0.25,'-0.8',pos=4,cex=1.2)
  text(0.4,0.75,'0.8',pos=4,cex=1.2)
  text(0.45,0.5,'SI',pos=4,cex=1.5)
  
  aspratio <- 1.25  # this is the aspect ratio of the output pdf
  imwidth <- 0.55
for (m in 1:4){
    plot(x=NULL,y=NULL, axes=FALSE, ann=FALSE, xlim=c(0,1), ylim=c(0,1))
for (f in 1:2){

  xstart <- 0.42*(f-1) - 0.05
  ystart <- 1-(0.5*f) - 0.05
  e1 <- readTIFF(paste("temp/SIheadF",f,'M',m,".tiff",sep=''))
  rasterImage(e1,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
}
  text(0.05,1,paste('(',letters[5+m],')',sep=''),cex=1.5)
  text(0.58,0.91,'1F',cex=1.5)
  text(0.42,0.03,'2F',cex=1.5)
}
  
dev.off()

for (f in 1:2){for (m in 1:4){file.remove(paste("temp/SIheadF",f,'M',m,".tiff",sep=''))}}
file.remove('temp/colourbar.tiff')

}
```

We calculated a modified saturation index that takes into account the inversion of the functions. This was defined as the difference between responses at the highest two mask contrasts (48% - 96%), scaled by the minimum of the function (we adjusted the index for the monocular mask to take into account the lower mask contrast used). Again, positive values imply acceleration of masking, values of 0 saturation, and negative values supersaturation, but this time applied to the mask signal. At electrode _Oz_, the saturation index was near or below zero for monocular and dichoptic masks at the first harmonic, and surround masks at the second harmonic. Across the scalp (Figure \@ref(fig:masksignals)f-i), a range of saturation indices were apparent, though the mean index overall was positive (SI = 0.1).

```{r masksignals, fig.cap="Summary of the effects of varying mask contrast. Panel (a) shows the predictions of a gain control model (equation 1) for different levels of mask contrast. In the linear model (black), the suppressive signal is a linear function of mask contrast. In the nonlinear model (red), the suppressive signal has itself passed through a nonlinear transducer function before suppressing the target. Panels (b - e) show empirical data for four mask types, at the first and second harmonic frequencies (black borders and black fills, respectively). Error bars and shaded regions show ±1 standard error of the mean across N = 21 participants. Panels (f - i) show how the modified saturation index varies across the scalp.", fig.align="center", echo=FALSE}

knitr::include_graphics('figures/masksignals.pdf')

```

# Discussion

We asked whether suppression from four types of mask could be best explained by changes in contrast gain or response gain. Data from two SSVEP experiments showed that at the first harmonic frequency, all four mask types were best explained by contrast gain control, with minimal influence from response gain. However at the second harmonic frequency, both types of gain control were apparent. There was also evidence that the strength of suppression, particularly from the surround, increased away from the occipital pole. Finally, we asked whether suppressive signals saturate before impacting the target, and found some evidence of this for monocular and dichoptic masks at the first harmonic, and surround masks at the second harmonic.

## Distinct suppressive pathways with a common outcome

Facilitation

## What is suppression for?

Mention normalization reweighting and optimal combination

# Acknowledgements

Supported by the Royal Society (grant number RG130121 to DHB). [Alex - should we acknowledge Damian Mannion here?]

# References




